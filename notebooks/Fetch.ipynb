{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0734cb-73e9-4c81-98a2-0de9be73a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31028e4b-682b-42a6-9796-fcb2f4da927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "products_file = \"/Users/sonalidarapu/Documents/PRODUCTS_TAKEHOME.csv\"\n",
    "transactions_file = \"/Users/sonalidarapu/Documents/TRANSACTION_TAKEHOME.csv\"\n",
    "users_file = \"/Users/sonalidarapu/Documents/USER_TAKEHOME.csv\"\n",
    "\n",
    "# Load the files into Pandas DataFrames\n",
    "df_products = pd.read_csv(products_file)\n",
    "df_transactions = pd.read_csv(transactions_file)\n",
    "df_users = pd.read_csv(users_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2251f2-2484-49fd-ad02-ea284062ce7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae976e15-5f9d-4312-8421-c9064c1d03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY_1</th>\n",
       "      <th>CATEGORY_2</th>\n",
       "      <th>CATEGORY_3</th>\n",
       "      <th>CATEGORY_4</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>BARCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Sexual Health</td>\n",
       "      <td>Conductivity Gels &amp; Lotions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.964944e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>Puffed Snacks</td>\n",
       "      <td>Cheese Curls &amp; Puffs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.327801e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care Accessories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLACEHOLDER MANUFACTURER</td>\n",
       "      <td>ELECSOP</td>\n",
       "      <td>4.618178e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Oral Care</td>\n",
       "      <td>Toothpaste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLGATE-PALMOLIVE</td>\n",
       "      <td>COLGATE</td>\n",
       "      <td>3.500047e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Medicines &amp; Treatments</td>\n",
       "      <td>Essential Oils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...</td>\n",
       "      <td>MAPLE HOLISTICS</td>\n",
       "      <td>8.068109e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
       "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
       "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
       "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
       "3  Health & Wellness               Oral Care                   Toothpaste   \n",
       "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
       "\n",
       "  CATEGORY_4                                       MANUFACTURER  \\\n",
       "0        NaN                                                NaN   \n",
       "1        NaN                                                NaN   \n",
       "2        NaN                           PLACEHOLDER MANUFACTURER   \n",
       "3        NaN                                  COLGATE-PALMOLIVE   \n",
       "4        NaN  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
       "\n",
       "             BRAND       BARCODE  \n",
       "0              NaN  7.964944e+11  \n",
       "1              NaN  2.327801e+10  \n",
       "2          ELECSOP  4.618178e+11  \n",
       "3          COLGATE  3.500047e+10  \n",
       "4  MAPLE HOLISTICS  8.068109e+11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transactions DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000d256-4041-4a3e-adc4-5623fb6e0c99</td>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>2024-08-21 14:19:06.539 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>63b73a7f3d310dceeabd4758</td>\n",
       "      <td>1.530001e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001455d-7a92-4a7b-a1d2-c747af1c8fd3</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>2024-07-20 09:50:24.206 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>62c08877baa38d1a1f6c211a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00017e0a-7851-42fb-bfab-0baa96e23586</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>2024-08-19 15:38:56.813 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>60842f207ac8b7729e472020</td>\n",
       "      <td>7.874223e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000239aa-3478-453d-801e-66a82e39c8af</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024-06-19 11:03:37.468 Z</td>\n",
       "      <td>FOOD LION</td>\n",
       "      <td>63fcd7cea4f8442c3386b589</td>\n",
       "      <td>7.833997e+11</td>\n",
       "      <td>zero</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-05 15:56:43.549 Z</td>\n",
       "      <td>RANDALLS</td>\n",
       "      <td>6193231ae9b3d75037b0f928</td>\n",
       "      <td>4.790050e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RECEIPT_ID PURCHASE_DATE  \\\n",
       "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
       "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
       "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
       "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
       "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
       "\n",
       "                   SCAN_DATE STORE_NAME                   USER_ID  \\\n",
       "0  2024-08-21 14:19:06.539 Z    WALMART  63b73a7f3d310dceeabd4758   \n",
       "1  2024-07-20 09:50:24.206 Z       ALDI  62c08877baa38d1a1f6c211a   \n",
       "2  2024-08-19 15:38:56.813 Z    WALMART  60842f207ac8b7729e472020   \n",
       "3  2024-06-19 11:03:37.468 Z  FOOD LION  63fcd7cea4f8442c3386b589   \n",
       "4  2024-07-05 15:56:43.549 Z   RANDALLS  6193231ae9b3d75037b0f928   \n",
       "\n",
       "        BARCODE FINAL_QUANTITY FINAL_SALE  \n",
       "0  1.530001e+10           1.00             \n",
       "1           NaN           zero       1.49  \n",
       "2  7.874223e+10           1.00             \n",
       "3  7.833997e+11           zero       3.49  \n",
       "4  4.790050e+10           1.00             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Users DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ef3b4f17053ab141787697d</td>\n",
       "      <td>2020-06-24 20:17:54.000 Z</td>\n",
       "      <td>2000-08-11 00:00:00.000 Z</td>\n",
       "      <td>CA</td>\n",
       "      <td>es-419</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ff220d383fcfc12622b96bc</td>\n",
       "      <td>2021-01-03 19:53:55.000 Z</td>\n",
       "      <td>2001-09-24 04:00:00.000 Z</td>\n",
       "      <td>PA</td>\n",
       "      <td>en</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6477950aa55bb77a0e27ee10</td>\n",
       "      <td>2023-05-31 18:42:18.000 Z</td>\n",
       "      <td>1994-10-28 00:00:00.000 Z</td>\n",
       "      <td>FL</td>\n",
       "      <td>es-419</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658a306e99b40f103b63ccf8</td>\n",
       "      <td>2023-12-26 01:46:22.000 Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>653cf5d6a225ea102b7ecdc2</td>\n",
       "      <td>2023-10-28 11:51:50.000 Z</td>\n",
       "      <td>1972-03-19 00:00:00.000 Z</td>\n",
       "      <td>PA</td>\n",
       "      <td>en</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID               CREATED_DATE  \\\n",
       "0  5ef3b4f17053ab141787697d  2020-06-24 20:17:54.000 Z   \n",
       "1  5ff220d383fcfc12622b96bc  2021-01-03 19:53:55.000 Z   \n",
       "2  6477950aa55bb77a0e27ee10  2023-05-31 18:42:18.000 Z   \n",
       "3  658a306e99b40f103b63ccf8  2023-12-26 01:46:22.000 Z   \n",
       "4  653cf5d6a225ea102b7ecdc2  2023-10-28 11:51:50.000 Z   \n",
       "\n",
       "                  BIRTH_DATE STATE LANGUAGE  GENDER  \n",
       "0  2000-08-11 00:00:00.000 Z    CA   es-419  female  \n",
       "1  2001-09-24 04:00:00.000 Z    PA       en  female  \n",
       "2  1994-10-28 00:00:00.000 Z    FL   es-419  female  \n",
       "3                        NaN    NC       en     NaN  \n",
       "4  1972-03-19 00:00:00.000 Z    PA       en  female  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few rows\n",
    "print(\"Products DataFrame:\")\n",
    "display(df_products.head())\n",
    "\n",
    "print(\"\\nTransactions DataFrame:\")\n",
    "display(df_transactions.head())\n",
    "\n",
    "print(\"\\nUsers DataFrame:\")\n",
    "display(df_users.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b87aa0-6f15-4989-96df-5ce7281b379b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products DataFrame Shape: (845552, 7)\n",
      "Transactions DataFrame Shape: (50000, 8)\n",
      "Users DataFrame Shape: (100000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Products DataFrame Shape:\", df_products.shape)\n",
    "print(\"Transactions DataFrame Shape:\", df_transactions.shape)\n",
    "print(\"Users DataFrame Shape:\", df_users.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330ff15c-c65f-4295-9caf-5c10e0b49df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Products DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 845552 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   CATEGORY_1    845441 non-null  object \n",
      " 1   CATEGORY_2    844128 non-null  object \n",
      " 2   CATEGORY_3    784986 non-null  object \n",
      " 3   CATEGORY_4    67459 non-null   object \n",
      " 4   MANUFACTURER  619078 non-null  object \n",
      " 5   BRAND         619080 non-null  object \n",
      " 6   BARCODE       841527 non-null  float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 45.2+ MB\n",
      "\n",
      "Transactions DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   RECEIPT_ID      50000 non-null  object \n",
      " 1   PURCHASE_DATE   50000 non-null  object \n",
      " 2   SCAN_DATE       50000 non-null  object \n",
      " 3   STORE_NAME      50000 non-null  object \n",
      " 4   USER_ID         50000 non-null  object \n",
      " 5   BARCODE         44238 non-null  float64\n",
      " 6   FINAL_QUANTITY  50000 non-null  object \n",
      " 7   FINAL_SALE      50000 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 3.1+ MB\n",
      "\n",
      "Users DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   ID            100000 non-null  object\n",
      " 1   CREATED_DATE  100000 non-null  object\n",
      " 2   BIRTH_DATE    96325 non-null   object\n",
      " 3   STATE         95188 non-null   object\n",
      " 4   LANGUAGE      69492 non-null   object\n",
      " 5   GENDER        94108 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProducts DataFrame Info:\")\n",
    "df_products.info()\n",
    "\n",
    "print(\"\\nTransactions DataFrame Info:\")\n",
    "df_transactions.info()\n",
    "\n",
    "print(\"\\nUsers DataFrame Info:\")\n",
    "df_users.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1a1e795-63b6-48bf-a171-acd9b93c6062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Products DataFrame:\n",
      "CATEGORY_1         111\n",
      "CATEGORY_2        1424\n",
      "CATEGORY_3       60566\n",
      "CATEGORY_4      778093\n",
      "MANUFACTURER    226474\n",
      "BRAND           226472\n",
      "BARCODE           4025\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Transactions DataFrame:\n",
      "RECEIPT_ID           0\n",
      "PURCHASE_DATE        0\n",
      "SCAN_DATE            0\n",
      "STORE_NAME           0\n",
      "USER_ID              0\n",
      "BARCODE           5762\n",
      "FINAL_QUANTITY       0\n",
      "FINAL_SALE           0\n",
      "dtype: int64\n",
      "\n",
      "Missing Values in Users DataFrame:\n",
      "ID                  0\n",
      "CREATED_DATE        0\n",
      "BIRTH_DATE       3675\n",
      "STATE            4812\n",
      "LANGUAGE        30508\n",
      "GENDER           5892\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values in Products DataFrame:\")\n",
    "print(df_products.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Transactions DataFrame:\")\n",
    "print(df_transactions.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing Values in Users DataFrame:\")\n",
    "print(df_users.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0c57d4-19a6-4ea6-8906-8f3117acb4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Products DataFrame before handling:\n",
      "CATEGORY_1      0\n",
      "CATEGORY_2      0\n",
      "CATEGORY_3      0\n",
      "CATEGORY_4      0\n",
      "MANUFACTURER    0\n",
      "BRAND           0\n",
      "BARCODE         0\n",
      "dtype: int64\n",
      "\n",
      "Missing BARCODE values in Products: 0\n",
      "\n",
      "Missing Values in Products DataFrame after handling:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_2591/3877111970.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"CATEGORY_1\"].fillna(df_products[\"CATEGORY_1\"].mode()[0], inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_2591/3877111970.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"CATEGORY_2\"].fillna(df_products[\"CATEGORY_2\"].mode()[0], inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_2591/3877111970.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"CATEGORY_3\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_2591/3877111970.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"CATEGORY_4\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_2591/3877111970.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"MANUFACTURER\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_2591/3877111970.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"BRAND\"].fillna(\"Unknown\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORY_1      0\n",
      "CATEGORY_2      0\n",
      "CATEGORY_3      0\n",
      "CATEGORY_4      0\n",
      "MANUFACTURER    0\n",
      "BRAND           0\n",
      "BARCODE         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the missing values in the Products DataFrame\n",
    "print(\"\\nMissing Values in Products DataFrame before handling:\")\n",
    "print(df_products.isnull().sum())\n",
    "\n",
    "# Fill missing product categories using mode (most frequent value)\n",
    "df_products[\"CATEGORY_1\"].fillna(df_products[\"CATEGORY_1\"].mode()[0], inplace=True)\n",
    "df_products[\"CATEGORY_2\"].fillna(df_products[\"CATEGORY_2\"].mode()[0], inplace=True)\n",
    "\n",
    "# Fill CATEGORY_3 and CATEGORY_4 with 'Unknown' due to high missing values\n",
    "df_products[\"CATEGORY_3\"].fillna(\"Unknown\", inplace=True)\n",
    "df_products[\"CATEGORY_4\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Fill MANUFACTURER and BRAND with 'Unknown' as they have a high percentage of missing values\n",
    "df_products[\"MANUFACTURER\"].fillna(\"Unknown\", inplace=True)\n",
    "df_products[\"BRAND\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Investigate missing BARCODE values\n",
    "print(\"\\nMissing BARCODE values in Products:\", df_products[\"BARCODE\"].isnull().sum())\n",
    "\n",
    "# Convert BARCODE to string type and fill missing values with 'Unknown'\n",
    "df_products[\"BARCODE\"] = df_products[\"BARCODE\"].astype(str).fillna(\"Unknown\")\n",
    "\n",
    "# Confirm missing values are handled\n",
    "print(\"\\nMissing Values in Products DataFrame after handling:\")\n",
    "print(df_products.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8c728f-b2f9-44b2-a102-3d977475bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values in df_products (Products DataFrame)\n",
    "\n",
    "df_products[\"CATEGORY_1\"] = df_products[\"CATEGORY_1\"].fillna(df_products[\"CATEGORY_1\"].mode()[0])\n",
    "df_products[\"CATEGORY_2\"] = df_products[\"CATEGORY_2\"].fillna(df_products[\"CATEGORY_2\"].mode()[0])\n",
    "df_products[\"CATEGORY_3\"] = df_products[\"CATEGORY_3\"].fillna(\"Unknown\")\n",
    "df_products[\"CATEGORY_4\"] = df_products[\"CATEGORY_4\"].fillna(\"Unknown\")\n",
    "df_products[\"MANUFACTURER\"] = df_products[\"MANUFACTURER\"].fillna(\"Unknown\")\n",
    "df_products[\"BRAND\"] = df_products[\"BRAND\"].fillna(\"Unknown\")\n",
    "df_products[\"BARCODE\"] = df_products[\"BARCODE\"].astype(str).fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1127cd7b-5347-45c3-b776-2fc9ceee5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing product categories using mode (most frequent value)\n",
    "df_products = df_products.assign(\n",
    "    CATEGORY_1=df_products[\"CATEGORY_1\"].fillna(df_products[\"CATEGORY_1\"].mode()[0]),\n",
    "    CATEGORY_2=df_products[\"CATEGORY_2\"].fillna(df_products[\"CATEGORY_2\"].mode()[0]),\n",
    "    CATEGORY_3=df_products[\"CATEGORY_3\"].fillna(\"Unknown\"),\n",
    "    CATEGORY_4=df_products[\"CATEGORY_4\"].fillna(\"Unknown\"),\n",
    "    MANUFACTURER=df_products[\"MANUFACTURER\"].fillna(\"Unknown\"),\n",
    "    BRAND=df_products[\"BRAND\"].fillna(\"Unknown\"),\n",
    "    BARCODE=df_products[\"BARCODE\"].astype(str).fillna(\"Unknown\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f93a5de4-ed53-42bd-a3e7-e5e8ccdcbb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Products DataFrame Data Types:\n",
      "CATEGORY_1       object\n",
      "CATEGORY_2       object\n",
      "CATEGORY_3       object\n",
      "CATEGORY_4       object\n",
      "MANUFACTURER     object\n",
      "BRAND            object\n",
      "BARCODE         float64\n",
      "dtype: object\n",
      "\n",
      "Transactions DataFrame Data Types:\n",
      "RECEIPT_ID         object\n",
      "PURCHASE_DATE      object\n",
      "SCAN_DATE          object\n",
      "STORE_NAME         object\n",
      "USER_ID            object\n",
      "BARCODE           float64\n",
      "FINAL_QUANTITY     object\n",
      "FINAL_SALE         object\n",
      "dtype: object\n",
      "\n",
      "Users DataFrame Data Types:\n",
      "ID              object\n",
      "CREATED_DATE    object\n",
      "BIRTH_DATE      object\n",
      "STATE           object\n",
      "LANGUAGE        object\n",
      "GENDER          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProducts DataFrame Data Types:\")\n",
    "print(df_products.dtypes)\n",
    "\n",
    "print(\"\\nTransactions DataFrame Data Types:\")\n",
    "print(df_transactions.dtypes)\n",
    "\n",
    "print(\"\\nUsers DataFrame Data Types:\")\n",
    "print(df_users.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc5fcf1-404f-41a6-81b5-52856cfa1248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BARCODE to string (it should not be a float)\n",
    "df_products[\"BARCODE\"] = df_products[\"BARCODE\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4b94198-bd40-4f5a-9454-eb4f6b58f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df_transactions[\"PURCHASE_DATE\"] = pd.to_datetime(df_transactions[\"PURCHASE_DATE\"], errors=\"coerce\")\n",
    "df_transactions[\"SCAN_DATE\"] = pd.to_datetime(df_transactions[\"SCAN_DATE\"], errors=\"coerce\")\n",
    "\n",
    "# Convert BARCODE to string for consistency with df_products\n",
    "df_transactions[\"BARCODE\"] = df_transactions[\"BARCODE\"].astype(str)\n",
    "\n",
    "# Convert FINAL_QUANTITY and FINAL_SALE to float\n",
    "df_transactions[\"FINAL_QUANTITY\"] = pd.to_numeric(df_transactions[\"FINAL_QUANTITY\"], errors=\"coerce\")\n",
    "df_transactions[\"FINAL_SALE\"] = pd.to_numeric(df_transactions[\"FINAL_SALE\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2c3541b-407a-403a-8e49-6bb4f3d5e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CREATED_DATE and BIRTH_DATE to datetime format\n",
    "df_users[\"CREATED_DATE\"] = pd.to_datetime(df_users[\"CREATED_DATE\"], errors=\"coerce\")\n",
    "df_users[\"BIRTH_DATE\"] = pd.to_datetime(df_users[\"BIRTH_DATE\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084c02a6-7cfe-44e4-b39b-87e42f9b9b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated Data Types for Products DataFrame:\n",
      "CATEGORY_1      object\n",
      "CATEGORY_2      object\n",
      "CATEGORY_3      object\n",
      "CATEGORY_4      object\n",
      "MANUFACTURER    object\n",
      "BRAND           object\n",
      "BARCODE         object\n",
      "dtype: object\n",
      "\n",
      "Updated Data Types for Transactions DataFrame:\n",
      "RECEIPT_ID                object\n",
      "PURCHASE_DATE     datetime64[ns]\n",
      "SCAN_DATE         datetime64[ns]\n",
      "STORE_NAME                object\n",
      "USER_ID                   object\n",
      "BARCODE                   object\n",
      "FINAL_QUANTITY           float64\n",
      "FINAL_SALE               float64\n",
      "dtype: object\n",
      "\n",
      "Updated Data Types for Users DataFrame:\n",
      "ID                      object\n",
      "CREATED_DATE    datetime64[ns]\n",
      "BIRTH_DATE      datetime64[ns]\n",
      "STATE                   object\n",
      "LANGUAGE                object\n",
      "GENDER                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUpdated Data Types for Products DataFrame:\")\n",
    "print(df_products.dtypes)\n",
    "\n",
    "print(\"\\nUpdated Data Types for Transactions DataFrame:\")\n",
    "print(df_transactions.dtypes)\n",
    "\n",
    "print(\"\\nUpdated Data Types for Users DataFrame:\")\n",
    "print(df_users.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02fdacd6-ba52-4844-8e7a-ada66af3ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert timezone-aware datetime columns to naive (optional, only if needed)\n",
    "df_transactions[\"SCAN_DATE\"] = df_transactions[\"SCAN_DATE\"].dt.tz_localize(None)\n",
    "df_users[\"CREATED_DATE\"] = df_users[\"CREATED_DATE\"].dt.tz_localize(None)\n",
    "df_users[\"BIRTH_DATE\"] = df_users[\"BIRTH_DATE\"].dt.tz_localize(None)\n",
    "\n",
    "# Clean up BARCODE (remove spaces & leading zeros if needed)\n",
    "df_products[\"BARCODE\"] = df_products[\"BARCODE\"].str.strip()\n",
    "df_transactions[\"BARCODE\"] = df_transactions[\"BARCODE\"].str.strip()\n",
    "\n",
    "# Ensure numeric values have consistent decimal precision\n",
    "df_transactions[\"FINAL_QUANTITY\"] = df_transactions[\"FINAL_QUANTITY\"].round(2)\n",
    "df_transactions[\"FINAL_SALE\"] = df_transactions[\"FINAL_SALE\"].round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "578621c9-5afc-4320-941e-2f1e28182747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Number of transactions with missing BARCODEs: 19408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00017e0a-7851-42fb-bfab-0baa96e23586</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>2024-08-19 15:38:56.813</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>60842f207ac8b7729e472020</td>\n",
       "      <td>78742229751.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000239aa-3478-453d-801e-66a82e39c8af</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024-06-19 11:03:37.468</td>\n",
       "      <td>FOOD LION</td>\n",
       "      <td>63fcd7cea4f8442c3386b589</td>\n",
       "      <td>783399746536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-05 15:56:43.549</td>\n",
       "      <td>RANDALLS</td>\n",
       "      <td>6193231ae9b3d75037b0f928</td>\n",
       "      <td>47900501183.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000550b2-1480-4c07-950f-ff601f242152</td>\n",
       "      <td>2024-07-06</td>\n",
       "      <td>2024-07-06 19:27:48.586</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>5f850bc9cf9431165f3ac175</td>\n",
       "      <td>49200905548.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000e1d35-15e5-46c6-b6b3-33653ed3d27e</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>2024-08-13 18:21:07.931</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>61a6d926f998e47aad33db66</td>\n",
       "      <td>52000011227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RECEIPT_ID PURCHASE_DATE               SCAN_DATE  \\\n",
       "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18 2024-08-19 15:38:56.813   \n",
       "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18 2024-06-19 11:03:37.468   \n",
       "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04 2024-07-05 15:56:43.549   \n",
       "6  000550b2-1480-4c07-950f-ff601f242152    2024-07-06 2024-07-06 19:27:48.586   \n",
       "8  000e1d35-15e5-46c6-b6b3-33653ed3d27e    2024-08-13 2024-08-13 18:21:07.931   \n",
       "\n",
       "  STORE_NAME                   USER_ID         BARCODE  FINAL_QUANTITY  \\\n",
       "2    WALMART  60842f207ac8b7729e472020   78742229751.0             1.0   \n",
       "3  FOOD LION  63fcd7cea4f8442c3386b589  783399746536.0             NaN   \n",
       "4   RANDALLS  6193231ae9b3d75037b0f928   47900501183.0             1.0   \n",
       "6    WALMART  5f850bc9cf9431165f3ac175   49200905548.0             1.0   \n",
       "8    WALMART  61a6d926f998e47aad33db66   52000011227.0             1.0   \n",
       "\n",
       "   FINAL_SALE  \n",
       "2         NaN  \n",
       "3        3.49  \n",
       "4         NaN  \n",
       "6         NaN  \n",
       "8         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find transactions where BARCODE does not exist in Products\n",
    "missing_barcodes = df_transactions[~df_transactions[\"BARCODE\"].isin(df_products[\"BARCODE\"])]\n",
    "\n",
    "# Print count of missing BARCODEs\n",
    "print(f\"ðŸš¨ Number of transactions with missing BARCODEs: {len(missing_barcodes)}\")\n",
    "\n",
    "# Display a few rows of missing BARCODE transactions\n",
    "display(missing_barcodes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b298b9b6-d450-4f04-b126-3783a734733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Number of transactions with missing BARCODEs after formatting fix: 19408\n"
     ]
    }
   ],
   "source": [
    "# Convert BARCODE to string format and remove leading/trailing spaces\n",
    "df_products[\"BARCODE\"] = df_products[\"BARCODE\"].astype(str).str.strip()\n",
    "df_transactions[\"BARCODE\"] = df_transactions[\"BARCODE\"].astype(str).str.strip()\n",
    "\n",
    "# Check again if missing BARCODEs are reduced\n",
    "missing_barcodes = df_transactions[~df_transactions[\"BARCODE\"].isin(df_products[\"BARCODE\"])]\n",
    "print(f\"ðŸš¨ Number of transactions with missing BARCODEs after formatting fix: {len(missing_barcodes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d008691b-8bd3-4a1f-a88d-5cd92e9690c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Sample missing BARCODEs from Transactions that donâ€™t exist in Products:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['78742229751.0', '783399746536.0', '47900501183.0',\n",
       "       '49200905548.0', '52000011227.0', '51500247051.0', '46000288697.0',\n",
       "       '72945612815.0', '40945.0', '72250011372.0'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a few missing BARCODEs\n",
    "print(\"ðŸš¨ Sample missing BARCODEs from Transactions that donâ€™t exist in Products:\")\n",
    "display(missing_barcodes[\"BARCODE\"].unique()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cdd608f-d706-4c95-9c08-17fe91800248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure all values are strings first and handle missing values properly\n",
    "df_transactions[\"BARCODE\"] = df_transactions[\"BARCODE\"].astype(str).apply(\n",
    "    lambda x: str(int(float(x))) if x.replace('.', '', 1).isdigit() else \"Unknown\"\n",
    ")\n",
    "\n",
    "df_products[\"BARCODE\"] = df_products[\"BARCODE\"].astype(str).apply(\n",
    "    lambda x: str(int(float(x))) if x.replace('.', '', 1).isdigit() else \"Unknown\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7446dee-6d48-4fed-b810-01239111d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15300014978' 'Unknown' '681131411295' ... '34000432288' '79400445445'\n",
      " '74323095777']\n",
      "['796494407820' '23278011028' '461817824225' ... '100167154940'\n",
      " '75390755960' '796793337781']\n"
     ]
    }
   ],
   "source": [
    "print(df_transactions[\"BARCODE\"].unique())\n",
    "print(df_products[\"BARCODE\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0576d7a7-d5ab-43f1-84ed-b699fe4132e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_transactions[\"BARCODE\"].dtype)\n",
    "print(df_products[\"BARCODE\"].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc54d786-b52f-4ac3-bd9d-f9be61f201f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 RECEIPT_ID PURCHASE_DATE  \\\n",
      "1      0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
      "2      00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
      "3      000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
      "4      00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
      "6      000550b2-1480-4c07-950f-ff601f242152    2024-07-06   \n",
      "...                                     ...           ...   \n",
      "49991  840c30ae-bc0a-40a4-a47d-052ed0af2da2    2024-08-18   \n",
      "49992  68f74fb3-ccf2-41f3-896a-799eb9a80680    2024-08-13   \n",
      "49994  6cdf3c1a-78b3-4fb0-85fd-52e2f5b4731c    2024-06-26   \n",
      "49995  b5cd61a9-8033-4913-a5c4-fb3f65e3a321    2024-08-21   \n",
      "49998  42475141-bef4-4df2-aa37-72577e2512bb    2024-06-18   \n",
      "\n",
      "                    SCAN_DATE       STORE_NAME                   USER_ID  \\\n",
      "1     2024-07-20 09:50:24.206             ALDI  62c08877baa38d1a1f6c211a   \n",
      "2     2024-08-19 15:38:56.813          WALMART  60842f207ac8b7729e472020   \n",
      "3     2024-06-19 11:03:37.468        FOOD LION  63fcd7cea4f8442c3386b589   \n",
      "4     2024-07-05 15:56:43.549         RANDALLS  6193231ae9b3d75037b0f928   \n",
      "6     2024-07-06 19:27:48.586          WALMART  5f850bc9cf9431165f3ac175   \n",
      "...                       ...              ...                       ...   \n",
      "49991 2024-08-18 14:44:02.530           COSTCO  65b322787050d0a6206b3479   \n",
      "49992 2024-08-19 11:06:59.023  PEPPERIDGE FARM  64f4aee2b84ba41db3fb246a   \n",
      "49994 2024-07-01 11:00:39.769    HARRIS TEETER  5de7ec93ca63cc17893cdd14   \n",
      "49995 2024-08-31 14:13:08.634           TARGET  6154bcf098f885648de2f299   \n",
      "49998 2024-06-18 19:57:32.211    MARKET BASKET  6169912fac47744405af62b7   \n",
      "\n",
      "       BARCODE  FINAL_QUANTITY  FINAL_SALE  \n",
      "1      Unknown             NaN        1.49  \n",
      "2      Unknown             1.0         NaN  \n",
      "3      Unknown             NaN        3.49  \n",
      "4      Unknown             1.0         NaN  \n",
      "6      Unknown             1.0         NaN  \n",
      "...        ...             ...         ...  \n",
      "49991  Unknown             1.0       11.99  \n",
      "49992  Unknown             1.0        2.89  \n",
      "49994  Unknown             1.0        3.00  \n",
      "49995  Unknown             2.0        1.18  \n",
      "49998  Unknown             1.0        3.00  \n",
      "\n",
      "[25170 rows x 8 columns]\n",
      "               CATEGORY_1              CATEGORY_2             CATEGORY_3  \\\n",
      "9       Health & Wellness                   Candy                Unknown   \n",
      "124                Snacks      Jerky & Dried Meat                Unknown   \n",
      "147                Snacks                Crackers         Wheat Crackers   \n",
      "365     Health & Wellness               Hair Care                Shampoo   \n",
      "428     Health & Wellness                Eye Care  Contact Lens Solution   \n",
      "...                   ...                     ...                    ...   \n",
      "845070  Health & Wellness  Medicines & Treatments                Unknown   \n",
      "845187  Health & Wellness             Bath & Body                Unknown   \n",
      "845215             Snacks                   Candy                Unknown   \n",
      "845234  Health & Wellness               Oral Care                Unknown   \n",
      "845363  Health & Wellness               Skin Care       Facial Cleansers   \n",
      "\n",
      "       CATEGORY_4               MANUFACTURER                  BRAND  BARCODE  \n",
      "9         Unknown            CHURCH & DWIGHT               REPHRESH  Unknown  \n",
      "124       Unknown                    CONAGRA               SLIM JIM  Unknown  \n",
      "147       Unknown                  KELLANOVA                 CARR'S  Unknown  \n",
      "365       Unknown                   UNILEVER  APOTHECARE ESSENTIALS  Unknown  \n",
      "428       Unknown  BAUSCH + LOMB CORPORATION          BAUSCH + LOMB  Unknown  \n",
      "...           ...                        ...                    ...      ...  \n",
      "845070    Unknown          RECKITT BENCKISER                CEPACOL  Unknown  \n",
      "845187    Unknown          RECKITT BENCKISER                QUEEN V  Unknown  \n",
      "845215    Unknown                    PEPSICO                IMAGINE  Unknown  \n",
      "845234    Unknown                     BOIRON                 BOIRON  Unknown  \n",
      "845363    Unknown           BEIERSDORF, INC.             LA PRAIRIE  Unknown  \n",
      "\n",
      "[4025 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_transactions[~df_transactions[\"BARCODE\"].str.isnumeric()])\n",
    "print(df_products[~df_products[\"BARCODE\"].str.isnumeric()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "820c5726-35bb-4e5d-9b8a-cf2fb756fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BARCODE\n",
      "Unknown         25170\n",
      "511111503972      168\n",
      "511111001768      164\n",
      "311111224057      150\n",
      "49000000443       142\n",
      "                ...  \n",
      "28400744508         2\n",
      "28400321907         2\n",
      "51009009341         2\n",
      "73390013875         2\n",
      "74323095777         2\n",
      "Name: count, Length: 6563, dtype: int64\n",
      "BARCODE\n",
      "Unknown         4025\n",
      "11461821           2\n",
      "20146900           2\n",
      "3454206            2\n",
      "3462003            2\n",
      "                ... \n",
      "201126106403       1\n",
      "77260008473        1\n",
      "118226859316       1\n",
      "50700555331        1\n",
      "796793337781       1\n",
      "Name: count, Length: 841343, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_transactions[\"BARCODE\"].value_counts())\n",
    "print(df_products[\"BARCODE\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f69fe24-9671-4962-9eb7-7667302b5526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows in Products DataFrame: 0\n",
      "Duplicate Rows in Transactions DataFrame: 0\n",
      "Duplicate Rows in Users DataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDuplicate Rows in Products DataFrame:\", df_products.duplicated().sum())\n",
    "print(\"Duplicate Rows in Transactions DataFrame:\", df_transactions.duplicated().sum())\n",
    "print(\"Duplicate Rows in Users DataFrame:\", df_users.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90c2dc12-38c9-4814-a368-4ad645dd5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = df_products.drop_duplicates()\n",
    "df_transactions = df_transactions.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "272ca626-1c04-44a6-bd2c-8e1120906e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in GENDER column:\n",
      "['female' nan 'male' 'non_binary' 'transgender' 'prefer_not_to_say'\n",
      " 'not_listed' 'Non-Binary' 'unknown' 'not_specified'\n",
      " \"My gender isn't listed\" 'Prefer not to say']\n",
      "\n",
      "Unique values in LANGUAGE column:\n",
      "['es-419' 'en' nan]\n",
      "\n",
      "Unique values in FINAL_QUANTITY column:\n",
      "[1.00e+00      nan 2.00e+00 3.00e+00 4.00e+00 4.55e+00 2.83e+00 2.34e+00\n",
      " 4.60e-01 7.00e+00 1.80e+01 1.20e+01 5.00e+00 2.17e+00 2.30e-01 8.00e+00\n",
      " 1.35e+00 9.00e-02 2.58e+00 1.47e+00 1.60e+01 6.20e-01 1.24e+00 1.40e+00\n",
      " 5.10e-01 5.30e-01 1.69e+00 6.00e+00 2.39e+00 2.60e+00 1.00e+01 8.60e-01\n",
      " 1.54e+00 1.88e+00 2.93e+00 1.28e+00 6.50e-01 2.89e+00 1.44e+00 2.75e+00\n",
      " 1.81e+00 2.76e+02 8.70e-01 2.10e+00 3.33e+00 2.54e+00 2.20e+00 1.93e+00\n",
      " 1.34e+00 1.13e+00 2.19e+00 8.30e-01 2.61e+00 2.80e-01 1.50e+00 9.70e-01\n",
      " 2.40e-01 1.18e+00 6.22e+00 1.22e+00 1.23e+00 2.57e+00 1.07e+00 2.11e+00\n",
      " 4.80e-01 9.00e+00 3.11e+00 1.08e+00 5.53e+00 1.89e+00 1.00e-02 2.18e+00\n",
      " 1.99e+00 4.00e-02 2.25e+00 1.37e+00 3.02e+00 3.50e-01 9.90e-01 1.80e+00\n",
      " 3.24e+00 9.40e-01 2.04e+00 3.69e+00 7.00e-01 2.52e+00 2.27e+00]\n",
      "\n",
      "Unique values in FINAL_SALE column:\n",
      "[  nan  1.49  3.49 ... 11.02 20.17 42.38]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique values in GENDER column:\")\n",
    "print(df_users[\"GENDER\"].unique())\n",
    "\n",
    "print(\"\\nUnique values in LANGUAGE column:\")\n",
    "print(df_users[\"LANGUAGE\"].unique()[:10])  # Display first 10 unique values\n",
    "\n",
    "print(\"\\nUnique values in FINAL_QUANTITY column:\")\n",
    "print(df_transactions[\"FINAL_QUANTITY\"].unique())\n",
    "\n",
    "print(\"\\nUnique values in FINAL_SALE column:\")\n",
    "print(df_transactions[\"FINAL_SALE\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2088cde-e0c8-49ae-aa57-ebf1e1c99e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Unique values in GENDER column:\n",
      "['female' nan 'male' 'non_binary' 'transgender' 'not_specified'\n",
      " 'not_listed']\n",
      "\n",
      "Unique values in LANGUAGE column:\n",
      "['es-419' 'en' 'unknown']\n",
      "\n",
      "Unique values in FINAL_QUANTITY column:\n",
      "[0.   0.01 0.04 0.09 0.23 0.24 0.28 0.35 0.46 0.48 0.51 0.53 0.62 0.65\n",
      " 0.7  0.83 0.86 0.87 0.94 0.97]\n",
      "\n",
      "Unique values in FINAL_SALE column:\n",
      "[0.   0.01 0.03 0.04 0.05 0.07 0.09 0.1  0.12 0.13 0.14 0.17 0.18 0.2\n",
      " 0.21 0.22 0.24 0.25 0.26 0.28]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Handling GENDER inconsistencies\n",
    "df_users[\"GENDER\"] = df_users[\"GENDER\"].str.lower().str.replace(\" \", \"_\", regex=True)\n",
    "df_users[\"GENDER\"] = df_users[\"GENDER\"].replace({\n",
    "    \"prefer_not_to_say\": \"not_specified\",\n",
    "    \"non-binary\": \"non_binary\",\n",
    "    \"my_gender_isn't_listed\": \"not_listed\",\n",
    "    \"unknown\": \"not_specified\"\n",
    "})\n",
    "\n",
    "# Print unique values in GENDER column\n",
    "print(\"\\nCleaned Unique values in GENDER column:\")\n",
    "print(df_users[\"GENDER\"].unique())\n",
    "\n",
    "# Handling LANGUAGE inconsistencies (if more values exist)\n",
    "df_users[\"LANGUAGE\"] = df_users[\"LANGUAGE\"].fillna(\"unknown\")\n",
    "\n",
    "# Print first 10 unique values in LANGUAGE column\n",
    "print(\"\\nUnique values in LANGUAGE column:\")\n",
    "print(df_users[\"LANGUAGE\"].unique()[:10])\n",
    "\n",
    "# Handling NaN values in FINAL_QUANTITY & FINAL_SALE\n",
    "df_transactions[\"FINAL_QUANTITY\"] = df_transactions[\"FINAL_QUANTITY\"].fillna(0)\n",
    "df_transactions[\"FINAL_SALE\"] = df_transactions[\"FINAL_SALE\"].fillna(0)\n",
    "\n",
    "# Convert values to appropriate format (remove scientific notation)\n",
    "df_transactions[\"FINAL_QUANTITY\"] = df_transactions[\"FINAL_QUANTITY\"].round(2)\n",
    "df_transactions[\"FINAL_SALE\"] = df_transactions[\"FINAL_SALE\"].round(2)\n",
    "\n",
    "# Print unique values in FINAL_QUANTITY\n",
    "print(\"\\nUnique values in FINAL_QUANTITY column:\")\n",
    "print(np.sort(df_transactions[\"FINAL_QUANTITY\"].unique())[:20])  # Display first 20 sorted unique values\n",
    "\n",
    "# Print unique values in FINAL_SALE\n",
    "print(\"\\nUnique values in FINAL_SALE column:\")\n",
    "print(np.sort(df_transactions[\"FINAL_SALE\"].unique())[:20])  # Display first 20 sorted unique values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40b36574-372d-4f98-a99e-1cd144bd504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transactions with Unmatched Barcodes: 0\n"
     ]
    }
   ],
   "source": [
    "# Find barcodes in transactions that do not exist in products\n",
    "missing_barcodes = df_transactions[~df_transactions[\"BARCODE\"].isin(df_products[\"BARCODE\"])]\n",
    "print(\"\\nTransactions with Unmatched Barcodes:\", len(missing_barcodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103d4791-1b22-45bc-880d-438746bac586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"CATEGORY_4\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"MANUFACTURER\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_products[\"BRAND\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_users[\"GENDER\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_users[\"LANGUAGE\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_users[\"STATE\"].fillna(\"Unknown\", inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_transactions[\"FINAL_SALE\"].replace(\" \", np.nan, inplace=True)\n",
      "/var/folders/h5/rml158ks4jn32bq4xmsr74bh0000gn/T/ipykernel_88407/8624290.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_transactions[\"FINAL_QUANTITY\"].replace(\" \", np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values for categorical data\n",
    "df_products[\"CATEGORY_4\"].fillna(\"Unknown\", inplace=True)\n",
    "df_products[\"MANUFACTURER\"].fillna(\"Unknown\", inplace=True)\n",
    "df_products[\"BRAND\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "df_users[\"GENDER\"].fillna(\"Unknown\", inplace=True)\n",
    "df_users[\"LANGUAGE\"].fillna(\"Unknown\", inplace=True)\n",
    "df_users[\"STATE\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Convert empty spaces to NaN in transactions\n",
    "df_transactions[\"FINAL_SALE\"].replace(\" \", np.nan, inplace=True)\n",
    "df_transactions[\"FINAL_QUANTITY\"].replace(\" \", np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c725c358-b15c-45b3-a2b1-9c37cb19a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values After Cleaning:\n",
      "CATEGORY_1      0\n",
      "CATEGORY_2      0\n",
      "CATEGORY_3      0\n",
      "CATEGORY_4      0\n",
      "MANUFACTURER    0\n",
      "BRAND           0\n",
      "BARCODE         0\n",
      "dtype: int64\n",
      "RECEIPT_ID        0\n",
      "PURCHASE_DATE     0\n",
      "SCAN_DATE         0\n",
      "STORE_NAME        0\n",
      "USER_ID           0\n",
      "BARCODE           0\n",
      "FINAL_QUANTITY    0\n",
      "FINAL_SALE        0\n",
      "dtype: int64\n",
      "ID                 0\n",
      "CREATED_DATE       0\n",
      "BIRTH_DATE      3675\n",
      "STATE              0\n",
      "LANGUAGE           0\n",
      "GENDER             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values in categorical columns with 'Unknown'\n",
    "df_products[\"CATEGORY_4\"] = df_products[\"CATEGORY_4\"].fillna(\"Unknown\")\n",
    "df_products[\"MANUFACTURER\"] = df_products[\"MANUFACTURER\"].fillna(\"Unknown\")\n",
    "df_products[\"BRAND\"] = df_products[\"BRAND\"].fillna(\"Unknown\")\n",
    "\n",
    "df_users[\"GENDER\"] = df_users[\"GENDER\"].fillna(\"Unknown\")\n",
    "df_users[\"LANGUAGE\"] = df_users[\"LANGUAGE\"].fillna(\"Unknown\")\n",
    "df_users[\"STATE\"] = df_users[\"STATE\"].fillna(\"Unknown\")\n",
    "\n",
    "# Handling missing values in numerical fields\n",
    "df_transactions[\"FINAL_SALE\"] = df_transactions[\"FINAL_SALE\"].replace(\" \", np.nan).astype(float)\n",
    "df_transactions[\"FINAL_QUANTITY\"] = df_transactions[\"FINAL_QUANTITY\"].replace(\"zero\", \"0\").astype(float)\n",
    "\n",
    "# Verify if missing values are handled\n",
    "print(\"\\nMissing Values After Cleaning:\")\n",
    "print(df_products.isnull().sum())\n",
    "print(df_transactions.isnull().sum())\n",
    "print(df_users.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "957aeceb-7df9-43af-a2bf-8cca70d86843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions[\"PURCHASE_DATE\"] = pd.to_datetime(df_transactions[\"PURCHASE_DATE\"], errors=\"coerce\")\n",
    "df_transactions[\"SCAN_DATE\"] = pd.to_datetime(df_transactions[\"SCAN_DATE\"], errors=\"coerce\")\n",
    "df_users[\"CREATED_DATE\"] = pd.to_datetime(df_users[\"CREATED_DATE\"], errors=\"coerce\")\n",
    "df_users[\"BIRTH_DATE\"] = pd.to_datetime(df_users[\"BIRTH_DATE\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60b90ccb-4847-4775-b57e-a9acc70272db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactions[\"FINAL_QUANTITY\"] = df_transactions[\"FINAL_QUANTITY\"].replace(\"zero\", \"0\").astype(float)\n",
    "df_transactions[\"FINAL_SALE\"] = df_transactions[\"FINAL_SALE\"].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3a69134-c1ef-4b6f-ab21-a4aad2850032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Transactions with missing BARCODEs: 0\n"
     ]
    }
   ],
   "source": [
    "missing_barcodes = df_transactions[~df_transactions[\"BARCODE\"].isin(df_products[\"BARCODE\"])]\n",
    "print(f\"ðŸš¨ Transactions with missing BARCODEs: {len(missing_barcodes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd194ed2-8405-4691-9037-ea56f53c41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 RECEIPT_ID PURCHASE_DATE  \\\n",
      "0      0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
      "2      00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
      "4      00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
      "6      000550b2-1480-4c07-950f-ff601f242152    2024-07-06   \n",
      "8      000e1d35-15e5-46c6-b6b3-33653ed3d27e    2024-08-13   \n",
      "...                                     ...           ...   \n",
      "49913  1c9eca43-ec4f-4baa-aecc-8f709dfe59b1    2024-08-09   \n",
      "49926  1a174704-9eaf-40cf-8767-c5322e2e0059    2024-08-17   \n",
      "49927  e12c7606-6896-4c77-973d-6582b54a3f35    2024-08-20   \n",
      "49933  ad9ba0d1-7783-433b-9bb5-7ed8b4581365    2024-08-20   \n",
      "49935  c556a06c-70fd-4263-9aca-f798acbe555f    2024-08-22   \n",
      "\n",
      "                    SCAN_DATE STORE_NAME                   USER_ID  \\\n",
      "0     2024-08-21 14:19:06.539    WALMART  63b73a7f3d310dceeabd4758   \n",
      "2     2024-08-19 15:38:56.813    WALMART  60842f207ac8b7729e472020   \n",
      "4     2024-07-05 15:56:43.549   RANDALLS  6193231ae9b3d75037b0f928   \n",
      "6     2024-07-06 19:27:48.586    WALMART  5f850bc9cf9431165f3ac175   \n",
      "8     2024-08-13 18:21:07.931    WALMART  61a6d926f998e47aad33db66   \n",
      "...                       ...        ...                       ...   \n",
      "49913 2024-08-09 17:24:26.923        CVS  5c3cf58a8b40e528f433762c   \n",
      "49926 2024-08-18 08:28:59.595        CVS  5e6d679aed3d81139305e0e9   \n",
      "49927 2024-08-20 18:56:28.393        CVS  621b95b47bbb0c342114d9b3   \n",
      "49933 2024-08-20 20:00:05.950        CVS  5eef4c9bef174d44fd744362   \n",
      "49935 2024-08-22 15:41:59.962        CVS  63b3499e9f3fc9c75473c647   \n",
      "\n",
      "           BARCODE  FINAL_QUANTITY  FINAL_SALE  \n",
      "0      15300014978             1.0         0.0  \n",
      "2          Unknown             1.0         0.0  \n",
      "4          Unknown             1.0         0.0  \n",
      "6          Unknown             1.0         0.0  \n",
      "8          Unknown             1.0         0.0  \n",
      "...            ...             ...         ...  \n",
      "49913      Unknown             1.0         0.0  \n",
      "49926      Unknown             1.0         0.0  \n",
      "49927      Unknown             1.0         0.0  \n",
      "49933      Unknown             1.0         0.0  \n",
      "49935      Unknown             1.0         0.0  \n",
      "\n",
      "[12973 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_transactions[df_transactions[\"FINAL_SALE\"] < 0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f06227a9-ef70-44b0-a14c-1e0477e2c656",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n\n    SELECT \n        t.BRAND,\n        COUNT(DISTINCT t.RECEIPT_ID) AS receipt_count\n    FROM df_transactions t\n    JOIN df_users u ON t.USER_ID = u.USER_ID\n    WHERE u.AGE >= 21\n    GROUP BY t.BRAND\n;\n': no such column: t.BRAND",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: t.BRAND",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 25\u001b[0m\n\u001b[1;32m     12\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m;\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Execute the query and store results in a DataFrame\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m top_5_brands \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query, conn)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(top_5_brands)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Close the database connection\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\n\n    SELECT \n        t.BRAND,\n        COUNT(DISTINCT t.RECEIPT_ID) AS receipt_count\n    FROM df_transactions t\n    JOIN df_users u ON t.USER_ID = u.USER_ID\n    WHERE u.AGE >= 21\n    GROUP BY t.BRAND\n;\n': no such column: t.BRAND"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite (assuming df_users and df_transactions exist)\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL query using subqueries\n",
    "query = \"\"\"\n",
    "\n",
    "    SELECT \n",
    "        t.BRAND,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS receipt_count\n",
    "    FROM df_transactions t\n",
    "    JOIN df_users u ON t.USER_ID = u.USER_ID\n",
    "    WHERE u.AGE >= 21\n",
    "    GROUP BY t.BRAND\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "top_5_brands = pd.read_sql_query(query, conn)\n",
    "print(top_5_brands)\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display results\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Top 5 Brands by Receipts Scanned (Users 21+)\", dataframe=top_5_brands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c915bd2-e61a-4ca0-bcab-4eecb6a3d97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RECEIPT_ID', 'PURCHASE_DATE', 'SCAN_DATE', 'STORE_NAME', 'USER_ID',\n",
      "       'BARCODE', 'FINAL_QUANTITY', 'FINAL_SALE'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'CREATED_DATE', 'BIRTH_DATE', 'STATE', 'LANGUAGE', 'GENDER'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_transactions.columns)  # Check column names in transactions dataset\n",
    "print(df_users.columns)  # Check column names in users dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "994801a4-ddf3-4bb8-9766-396a7e40320d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   BRAND  receipt_count\n",
      "0               REPHRESH             55\n",
      "1               SLIM JIM             55\n",
      "2                 CARR'S             55\n",
      "3  APOTHECARE ESSENTIALS             55\n",
      "4          BAUSCH + LOMB             55\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure AGE is calculated from BIRTH_DATE\n",
    "df_users[\"AGE\"] = pd.to_datetime(\"today\").year - pd.to_datetime(df_users[\"BIRTH_DATE\"]).dt.year\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"df_products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL query with AGE calculation\n",
    "query = \"\"\"\n",
    "SELECT p.BRAND, receipt_count \n",
    "FROM (\n",
    "    SELECT \n",
    "        t.BARCODE,  \n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS receipt_count\n",
    "    FROM df_transactions t\n",
    "    JOIN (\n",
    "        SELECT ID, \n",
    "               (strftime('%Y', 'now') - strftime('%Y', BIRTH_DATE)) AS AGE\n",
    "        FROM df_users\n",
    "    ) u ON t.USER_ID = u.ID\n",
    "    WHERE u.AGE >= 21\n",
    "    GROUP BY t.BARCODE\n",
    ") sub\n",
    "JOIN df_products p ON sub.BARCODE = p.BARCODE  \n",
    "ORDER BY receipt_count DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "top_5_brands = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(top_5_brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22aed2f0-fc93-46b3-a937-ad5e9772faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       BRAND  total_sales\n",
      "0                    Unknown     88315.89\n",
      "1  ANNIE'S HOMEGROWN GROCERY      8614.56\n",
      "2                   BAREFOOT      8255.62\n",
      "3                       DOVE      7939.56\n",
      "4                      ORIBE      7537.74\n",
      "5              SHEA MOISTURE      7178.80\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Ensure CREATED_DATE is in datetime format before inserting into SQLite\n",
    "df_users[\"CREATED_DATE\"] = pd.to_datetime(df_users[\"CREATED_DATE\"])\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"df_products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL query using SQLite to find top 5 brands by sales among users with accounts at least 6 months old\n",
    "query = \"\"\"\n",
    "WITH eligible_users AS (\n",
    "    SELECT ID \n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    ")\n",
    "SELECT p.BRAND, SUM(t.FINAL_SALE) AS total_sales\n",
    "FROM df_transactions t\n",
    "JOIN eligible_users u ON t.USER_ID = u.ID\n",
    "JOIN df_products p ON t.BARCODE = p.BARCODE\n",
    "GROUP BY p.BRAND\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 6;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "top_5_brands_sales = pd.read_sql_query(query, conn)\n",
    "print(top_5_brands_sales)\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "021b0d7e-e69a-4058-868c-819aed107451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [USER_ID, active_months, total_spent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Ensure CREATED_DATE is in datetime format before inserting into SQLite\n",
    "df_users[\"CREATED_DATE\"] = pd.to_datetime(df_users[\"CREATED_DATE\"])\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL query to identify Fetch power users (active 6+ months, 10+ receipts per month, $500+ spending per month)\n",
    "query = \"\"\"\n",
    "WITH active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(t.FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 5 AND total_spending >= 5\n",
    ")\n",
    "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
    "FROM monthly_activity\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spent DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "power_users = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(power_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d554e375-ec58-4c55-add8-7e384bcf654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eligible_users\n",
      "0           98081\n",
      "                    USER_ID  receipt_count\n",
      "0  64e62de5ca929250373e6cf5             10\n",
      "1  62925c1be942f00613f7365e             10\n",
      "2  64063c8880552327897186a5              9\n",
      "3  6327a07aca87b39d76e03864              7\n",
      "4  624dca0770c07012cd5e6c03              7\n",
      "                    USER_ID  total_spending\n",
      "0  630789e1101ae272a4852287          925.64\n",
      "1  63af23db9f3fc9c7546fdbec          476.34\n",
      "2  650874eafe41d365c2ee11d2          267.29\n",
      "3  645add3bffe0d7e043ef1b63          227.93\n",
      "4  637257e75fdbb03aa198a310          194.14\n",
      "   missing_dates\n",
      "0              0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite (Assuming df_users and df_transactions exist)\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Step 1: Check if there are users with accounts older than 6 months\n",
    "query_check_users = \"\"\"\n",
    "SELECT COUNT(*) AS eligible_users \n",
    "FROM df_users \n",
    "WHERE CREATED_DATE <= DATE('now', '-6 months');\n",
    "\"\"\"\n",
    "eligible_users = pd.read_sql_query(query_check_users, conn)\n",
    "\n",
    "# Step 2: Check transaction activity (receipts scanned per user)\n",
    "query_check_receipts = \"\"\"\n",
    "SELECT USER_ID, COUNT(DISTINCT RECEIPT_ID) AS receipt_count\n",
    "FROM df_transactions\n",
    "GROUP BY USER_ID\n",
    "ORDER BY receipt_count DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "top_receipt_users = pd.read_sql_query(query_check_receipts, conn)\n",
    "\n",
    "# Step 3: Check user spending activity per user\n",
    "query_check_spending = \"\"\"\n",
    "SELECT USER_ID, SUM(FINAL_SALE) AS total_spending\n",
    "FROM df_transactions\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spending DESC\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "top_spending_users = pd.read_sql_query(query_check_spending, conn)\n",
    "\n",
    "# Step 4: Check if transactions have valid purchase dates\n",
    "query_check_purchase_dates = \"\"\"\n",
    "SELECT COUNT(*) AS missing_dates FROM df_transactions WHERE PURCHASE_DATE IS NULL;\n",
    "\"\"\"\n",
    "missing_dates = pd.read_sql_query(query_check_purchase_dates, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "print(eligible_users)\n",
    "print(top_receipt_users)\n",
    "print(top_spending_users)\n",
    "print(missing_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f59593c9-c5a3-4840-99b5-d3e8d9084f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [USER_ID, active_months, total_spent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Updated SQL query with lower thresholds (5+ receipts and $200+ spending)\n",
    "query = \"\"\"\n",
    "WITH active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(t.FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 5 AND total_spending >= 200\n",
    ")\n",
    "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
    "FROM monthly_activity\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spent DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "power_users = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(power_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d87228e-e891-4efd-9937-4bc007e7f854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [USER_ID, purchase_month, total_receipts, total_spending]\n",
      "Index: []\n",
      "   eligible_users\n",
      "0           98081\n",
      "   final_eligible_users\n",
      "0                     0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Step 3: Verify users with both 5+ receipts per month and $200+ spending per month\n",
    "query_step3 = \"\"\"\n",
    "SELECT USER_ID, \n",
    "       strftime('%Y-%m', PURCHASE_DATE) AS purchase_month,\n",
    "       COUNT(DISTINCT RECEIPT_ID) AS total_receipts,\n",
    "       SUM(FINAL_SALE) AS total_spending\n",
    "FROM df_transactions\n",
    "GROUP BY USER_ID, purchase_month\n",
    "HAVING total_receipts >= 5 AND total_spending >= 200\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "step3_results = pd.read_sql_query(query_step3, conn)\n",
    "\n",
    "# Step 4: Check how many users have accounts older than 6 months\n",
    "query_step4 = \"\"\"\n",
    "SELECT COUNT(*) AS eligible_users\n",
    "FROM df_users \n",
    "WHERE CREATED_DATE <= DATE('now', '-6 months');\n",
    "\"\"\"\n",
    "step4_results = pd.read_sql_query(query_step4, conn)\n",
    "\n",
    "# Step 5: Check final number of users meeting all conditions\n",
    "query_step5 = \"\"\"\n",
    "WITH active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(t.FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 5 AND total_spending >= 200\n",
    ")\n",
    "SELECT COUNT(*) AS final_eligible_users FROM monthly_activity;\n",
    "\"\"\"\n",
    "step5_results = pd.read_sql_query(query_step5, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(step3_results)\n",
    "print(step4_results)\n",
    "print(step5_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2698ed39-bb0e-4767-b9e2-5cf18204a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     USER_ID  active_months  total_spent\n",
      "0   643059f0838dd2651fb27f50              1        75.99\n",
      "1   62ffec490d9dbaff18c0a999              2        46.72\n",
      "2   5f4c9055e81e6f162e3f6fa8              1        37.96\n",
      "3   5d191765c8b1ba28e74e8463              1        34.96\n",
      "4   64dd9170516348066e7c4006              1        26.52\n",
      "5   6351760a3a4a3534d9393ecd              1        19.98\n",
      "6   6661ed1e7c0469953bfc76c4              1        18.60\n",
      "7   5b441360be53340f289b0795              1        18.32\n",
      "8   61730bba65abe727fff3fcf7              1        18.22\n",
      "9   6682b24786cc41b000ce5e77              1        17.30\n",
      "10  5ea899202244e629eacd6785              1        15.12\n",
      "11  5fd4fb485f410d44bae3a776              1        14.58\n",
      "12  6615dab878ee6750bbc350ea              1        13.96\n",
      "13  5fc12a8a16770448f92e56b8              1        13.18\n",
      "14  62b67b8e37e6e08b0774f2c4              1        12.98\n",
      "15  6528a0a388a3a884364d94dc              1        12.50\n",
      "16  61a58ac49c135b462ccddd1c              1        12.45\n",
      "17  5f9414c65896841696c17359              1        11.97\n",
      "18  62c09104baa38d1a1f6c260e              1        11.96\n",
      "19  631e23bc198485e89002613b              1        11.85\n",
      "20  632fc9dc0c625b72ae991f83              1        11.79\n",
      "21  62d86d9a1d76344f1a3602d9              1        11.71\n",
      "22  5bb79c65b0a16836db35bbf1              1        11.58\n",
      "23  5f21e60446f11314a16015de              1        10.38\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Step 1: Check if any users scan 5+ receipts per month\n",
    "query_check_receipts = \"\"\"\n",
    "SELECT USER_ID, COUNT(DISTINCT RECEIPT_ID) AS total_receipts\n",
    "FROM df_transactions\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_receipts DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "top_receipt_users = pd.read_sql_query(query_check_receipts, conn)\n",
    "\n",
    "# Step 2: Check the highest spenders per month\n",
    "query_check_spending = \"\"\"\n",
    "SELECT USER_ID, strftime('%Y-%m', PURCHASE_DATE) AS purchase_month, SUM(FINAL_SALE) AS total_spending\n",
    "FROM df_transactions\n",
    "GROUP BY USER_ID, purchase_month\n",
    "ORDER BY total_spending DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "top_spending_users = pd.read_sql_query(query_check_spending, conn)\n",
    "\n",
    "# Step 3: Adjusted query with lower criteria (3+ receipts, $100+ spending)\n",
    "query_adjusted = \"\"\"\n",
    "WITH active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(t.FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 1 AND total_spending > 10\n",
    ")\n",
    "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
    "FROM monthly_activity\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spent DESC;\n",
    "\"\"\"\n",
    "adjusted_results = pd.read_sql_query(query_adjusted, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(adjusted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee6c1590-6c00-4653-84c5-b0e9afb493ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Metric  Total Spending ($)\n",
      "0                       Min                0.00\n",
      "1      Q1 (25th percentile)                3.00\n",
      "2  Median (50th percentile)                5.99\n",
      "3      Q3 (75th percentile)               11.84\n",
      "4                       Max              925.64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_transactions is already loaded into the environment\n",
    "# Check if df_transactions exists before proceeding\n",
    "try:\n",
    "    df_transactions.head()\n",
    "except NameError:\n",
    "    print(\"Dataset 'df_transactions' is not loaded. Please upload it.\")\n",
    "\n",
    "# Compute spending distribution statistics\n",
    "spending_distribution = df_transactions.groupby(\"USER_ID\")[\"FINAL_SALE\"].sum()\n",
    "\n",
    "# Compute percentiles\n",
    "percentiles = np.percentile(spending_distribution, [0, 25, 50, 75, 100])\n",
    "\n",
    "# Create a boxplot to visualize spending distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(spending_distribution, vert=False, patch_artist=True)\n",
    "plt.title(\"Spending Distribution of Users\")\n",
    "plt.xlabel(\"Total Spending ($)\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Display spending distribution summary\n",
    "spending_summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Min\", \"Q1 (25th percentile)\", \"Median (50th percentile)\", \"Q3 (75th percentile)\", \"Max\"],\n",
    "    \"Total Spending ($)\": percentiles\n",
    "})\n",
    "print(spending_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6076ae0e-f234-42b8-86e4-3383e17cb659",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nWITH spending_percentiles AS (\n    SELECT total_spent\n    FROM (\n        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n        FROM df_transactions\n        GROUP BY USER_ID\n    )\n    ORDER BY total_spent DESC\n    LIMIT (SELECT COUNT(*) * 0.10 FROM df_transactions)  -- Selects top 10% of spenders\n),\nactive_users AS (\n    SELECT ID AS USER_ID\n    FROM df_users\n    WHERE CREATED_DATE <= DATE('now', '-6 months')\n),\nmonthly_activity AS (\n    SELECT \n        t.USER_ID, \n        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n        SUM(t.FINAL_SALE) AS total_spending\n    FROM df_transactions t\n    JOIN active_users u ON t.USER_ID = u.USER_ID\n    GROUP BY t.USER_ID, purchase_month\n    HAVING total_receipts >= 3 AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n)\nSELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\nFROM monthly_activity\nGROUP BY USER_ID\nORDER BY total_spent DESC;\n': datatype mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mIntegrityError\u001b[0m: datatype mismatch",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 46\u001b[0m\n\u001b[1;32m     12\u001b[0m query_top_spenders \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mWITH spending_percentiles AS (\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m    SELECT total_spent\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124mORDER BY total_spent DESC;\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Execute the query and store results in a DataFrame\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m top_power_users \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query_top_spenders, conn)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Close database connection\u001b[39;00m\n\u001b[1;32m     49\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nWITH spending_percentiles AS (\n    SELECT total_spent\n    FROM (\n        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n        FROM df_transactions\n        GROUP BY USER_ID\n    )\n    ORDER BY total_spent DESC\n    LIMIT (SELECT COUNT(*) * 0.10 FROM df_transactions)  -- Selects top 10% of spenders\n),\nactive_users AS (\n    SELECT ID AS USER_ID\n    FROM df_users\n    WHERE CREATED_DATE <= DATE('now', '-6 months')\n),\nmonthly_activity AS (\n    SELECT \n        t.USER_ID, \n        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n        SUM(t.FINAL_SALE) AS total_spending\n    FROM df_transactions t\n    JOIN active_users u ON t.USER_ID = u.USER_ID\n    GROUP BY t.USER_ID, purchase_month\n    HAVING total_receipts >= 3 AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n)\nSELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\nFROM monthly_activity\nGROUP BY USER_ID\nORDER BY total_spent DESC;\n': datatype mismatch"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL Query: Identify power users in the top 10% spenders with 3+ receipts per month\n",
    "query_top_spenders = \"\"\"\n",
    "WITH spending_percentiles AS (\n",
    "    SELECT total_spent\n",
    "    FROM (\n",
    "        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n",
    "        FROM df_transactions\n",
    "        GROUP BY USER_ID\n",
    "    )\n",
    "    ORDER BY total_spent DESC\n",
    "    LIMIT (SELECT COUNT(*) * 0.10 FROM df_transactions)  -- Selects top 10% of spenders\n",
    "),\n",
    "active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', t.PURCHASE_DATE) AS purchase_month,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(t.FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 3 AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n",
    ")\n",
    "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
    "FROM monthly_activity\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spent DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "top_power_users = pd.read_sql_query(query_top_spenders, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "print(top_power_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec2040e3-14de-4802-b7cc-2fe94b7d0c9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nWITH spending_percentiles AS (\n    SELECT CAST(total_spent AS FLOAT) AS total_spent\n    FROM (\n        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n        FROM df_transactions\n        GROUP BY USER_ID\n    )\n    ORDER BY total_spent DESC\n    LIMIT (SELECT COUNT(DISTINCT USER_ID) * 0.10 FROM df_transactions)  \n),\nactive_users AS (\n    SELECT ID AS USER_ID\n    FROM df_users\n    WHERE DATE(CREATED_DATE) <= DATE('now', '-6 months')\n),\nmonthly_activity AS (\n    SELECT \n        t.USER_ID, \n        strftime('%Y-%m', DATE(t.PURCHASE_DATE)) AS purchase_month,\n        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n        SUM(FINAL_SALE) AS total_spending\n    FROM df_transactions t\n    JOIN active_users u ON t.USER_ID = u.USER_ID\n    GROUP BY t.USER_ID, purchase_month\n    HAVING total_receipts >= 3 \n    AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n)\nSELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\nFROM monthly_activity\nGROUP BY USER_ID\nORDER BY total_spent DESC;\n': datatype mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mIntegrityError\u001b[0m: datatype mismatch",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 88\u001b[0m\n\u001b[1;32m     53\u001b[0m query_top_spenders \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124mWITH spending_percentiles AS (\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124m    SELECT CAST(total_spent AS FLOAT) AS total_spent\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124mORDER BY total_spent DESC;\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Execute the query and store results in a DataFrame\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m top_power_users \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query_top_spenders, conn)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Close database connection\u001b[39;00m\n\u001b[1;32m     91\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nWITH spending_percentiles AS (\n    SELECT CAST(total_spent AS FLOAT) AS total_spent\n    FROM (\n        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n        FROM df_transactions\n        GROUP BY USER_ID\n    )\n    ORDER BY total_spent DESC\n    LIMIT (SELECT COUNT(DISTINCT USER_ID) * 0.10 FROM df_transactions)  \n),\nactive_users AS (\n    SELECT ID AS USER_ID\n    FROM df_users\n    WHERE DATE(CREATED_DATE) <= DATE('now', '-6 months')\n),\nmonthly_activity AS (\n    SELECT \n        t.USER_ID, \n        strftime('%Y-%m', DATE(t.PURCHASE_DATE)) AS purchase_month,\n        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n        SUM(FINAL_SALE) AS total_spending\n    FROM df_transactions t\n    JOIN active_users u ON t.USER_ID = u.USER_ID\n    GROUP BY t.USER_ID, purchase_month\n    HAVING total_receipts >= 3 \n    AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n)\nSELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\nFROM monthly_activity\nGROUP BY USER_ID\nORDER BY total_spent DESC;\n': datatype mismatch"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Step 1: Check Column Datatypes Before Fixing\n",
    "df_info = pd.read_sql_query(\"PRAGMA table_info(df_transactions);\", conn)\n",
    "\n",
    "# Step 2: Convert FINAL_SALE to FLOAT if needed\n",
    "conn.execute(\"\"\"\n",
    "ALTER TABLE df_transactions ADD COLUMN FINAL_SALE_FLOAT FLOAT;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "UPDATE df_transactions \n",
    "SET FINAL_SALE_FLOAT = CAST(FINAL_SALE AS FLOAT) \n",
    "WHERE FINAL_SALE IS NOT NULL AND FINAL_SALE != '';\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "ALTER TABLE df_transactions DROP COLUMN FINAL_SALE;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "ALTER TABLE df_transactions RENAME COLUMN FINAL_SALE_FLOAT TO FINAL_SALE;\n",
    "\"\"\")\n",
    "\n",
    "# Step 3: Convert PURCHASE_DATE to DATE if needed\n",
    "conn.execute(\"\"\"\n",
    "ALTER TABLE df_transactions ADD COLUMN PURCHASE_DATE_DATE DATE;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "UPDATE df_transactions \n",
    "SET PURCHASE_DATE_DATE = DATE(PURCHASE_DATE) \n",
    "WHERE PURCHASE_DATE IS NOT NULL AND PURCHASE_DATE != '';\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "ALTER TABLE df_transactions DROP COLUMN PURCHASE_DATE;\n",
    "\"\"\")\n",
    "\n",
    "conn.execute(\"\"\"\n",
    "ALTER TABLE df_transactions RENAME COLUMN PURCHASE_DATE_DATE TO PURCHASE_DATE;\n",
    "\"\"\")\n",
    "\n",
    "# Step 4: Execute SQL Query After Fixing Datatypes\n",
    "query_top_spenders = \"\"\"\n",
    "WITH spending_percentiles AS (\n",
    "    SELECT CAST(total_spent AS FLOAT) AS total_spent\n",
    "    FROM (\n",
    "        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n",
    "        FROM df_transactions\n",
    "        GROUP BY USER_ID\n",
    "    )\n",
    "    ORDER BY total_spent DESC\n",
    "    LIMIT (SELECT COUNT(DISTINCT USER_ID) * 0.10 FROM df_transactions)  \n",
    "),\n",
    "active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE DATE(CREATED_DATE) <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', DATE(t.PURCHASE_DATE)) AS purchase_month,\n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 3 \n",
    "    AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n",
    ")\n",
    "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
    "FROM monthly_activity\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spent DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "top_power_users = pd.read_sql_query(query_top_spenders, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "# Display results\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Top 10% Spending Power Users\", dataframe=top_power_users)\n",
    "\n",
    "# Display updated table schema\n",
    "tools.display_dataframe_to_user(name=\"Updated Table Schema\", dataframe=df_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b44ce0a-3c30-4a77-b0a6-285484de092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Information for df_transactions:\n",
      "   cid            name       type  notnull dflt_value  pk\n",
      "0    0      RECEIPT_ID       TEXT        0       None   0\n",
      "1    1   PURCHASE_DATE  TIMESTAMP        0       None   0\n",
      "2    2       SCAN_DATE  TIMESTAMP        0       None   0\n",
      "3    3      STORE_NAME       TEXT        0       None   0\n",
      "4    4         USER_ID       TEXT        0       None   0\n",
      "5    5         BARCODE       TEXT        0       None   0\n",
      "6    6  FINAL_QUANTITY       REAL        0       None   0\n",
      "7    7      FINAL_SALE       REAL        0       None   0\n",
      "Column Information for df_users:\n",
      "   cid          name       type  notnull dflt_value  pk\n",
      "0    0            ID       TEXT        0       None   0\n",
      "1    1  CREATED_DATE  TIMESTAMP        0       None   0\n",
      "2    2    BIRTH_DATE  TIMESTAMP        0       None   0\n",
      "3    3         STATE       TEXT        0       None   0\n",
      "4    4      LANGUAGE       TEXT        0       None   0\n",
      "5    5        GENDER       TEXT        0       None   0\n",
      "6    6           AGE       REAL        0       None   0\n",
      "Updated Column Information for df_transactions:\n",
      "   cid            name       type  notnull dflt_value  pk\n",
      "0    0      RECEIPT_ID       TEXT        0       None   0\n",
      "1    1   PURCHASE_DATE  TIMESTAMP        0       None   0\n",
      "2    2       SCAN_DATE  TIMESTAMP        0       None   0\n",
      "3    3      STORE_NAME       TEXT        0       None   0\n",
      "4    4         USER_ID       TEXT        0       None   0\n",
      "5    5         BARCODE       TEXT        0       None   0\n",
      "6    6  FINAL_QUANTITY       REAL        0       None   0\n",
      "7    7      FINAL_SALE       REAL        0       None   0\n",
      "Updated Column Information for df_users:\n",
      "   cid          name       type  notnull dflt_value  pk\n",
      "0    0            ID       TEXT        0       None   0\n",
      "1    1  CREATED_DATE  TIMESTAMP        0       None   0\n",
      "2    2    BIRTH_DATE  TIMESTAMP        0       None   0\n",
      "3    3         STATE       TEXT        0       None   0\n",
      "4    4      LANGUAGE       TEXT        0       None   0\n",
      "5    5        GENDER       TEXT        0       None   0\n",
      "6    6           AGE       REAL        0       None   0\n",
      "Error executing query: Execution failed on sql '\n",
      "WITH spending_percentiles AS (\n",
      "    SELECT total_spent\n",
      "    FROM (\n",
      "        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n",
      "        FROM df_transactions\n",
      "        GROUP BY USER_ID\n",
      "    )\n",
      "    ORDER BY total_spent DESC\n",
      "    LIMIT (SELECT COUNT(DISTINCT USER_ID) * 0.10 FROM df_transactions)  \n",
      "),\n",
      "active_users AS (\n",
      "    SELECT ID AS USER_ID\n",
      "    FROM df_users\n",
      "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
      "),\n",
      "monthly_activity AS (\n",
      "    SELECT \n",
      "        t.USER_ID, \n",
      "        strftime('%Y-%m', PURCHASE_DATE) AS purchase_month,  \n",
      "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
      "        SUM(FINAL_SALE) AS total_spending\n",
      "    FROM df_transactions t\n",
      "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
      "    GROUP BY t.USER_ID, purchase_month\n",
      "    HAVING total_receipts >= 3 \n",
      "    AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n",
      ")\n",
      "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
      "FROM monthly_activity\n",
      "GROUP BY USER_ID\n",
      "ORDER BY total_spent DESC;\n",
      "': datatype mismatch\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Step 1: Load Data into SQLite (Ensure the Data Exists)\n",
    "try:\n",
    "    df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "    df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "except NameError:\n",
    "    print(\"Datasets not found. Please upload df_users and df_transactions again.\")\n",
    "\n",
    "# Step 2: Check Column Datatypes in df_transactions\n",
    "query_check_transactions_columns = \"PRAGMA table_info(df_transactions);\"\n",
    "df_transactions_info = pd.read_sql_query(query_check_transactions_columns, conn)\n",
    "print(\"Column Information for df_transactions:\")\n",
    "print(df_transactions_info)\n",
    "\n",
    "# Step 3: Check Column Datatypes in df_users\n",
    "query_check_users_columns = \"PRAGMA table_info(df_users);\"\n",
    "df_users_info = pd.read_sql_query(query_check_users_columns, conn)\n",
    "print(\"Column Information for df_users:\")\n",
    "print(df_users_info)\n",
    "\n",
    "# Step 4: Ensure FINAL_SALE is stored as FLOAT\n",
    "conn.execute(\"\"\"\n",
    "UPDATE df_transactions \n",
    "SET FINAL_SALE = CAST(FINAL_SALE AS FLOAT) \n",
    "WHERE FINAL_SALE IS NOT NULL AND FINAL_SALE != '';\n",
    "\"\"\")\n",
    "\n",
    "# Step 5: Ensure PURCHASE_DATE is stored as DATE\n",
    "conn.execute(\"\"\"\n",
    "UPDATE df_transactions \n",
    "SET PURCHASE_DATE = DATE(PURCHASE_DATE) \n",
    "WHERE PURCHASE_DATE IS NOT NULL AND PURCHASE_DATE != '';\n",
    "\"\"\")\n",
    "\n",
    "# Step 6: Ensure CREATED_DATE is stored as DATE\n",
    "conn.execute(\"\"\"\n",
    "UPDATE df_users \n",
    "SET CREATED_DATE = DATE(CREATED_DATE) \n",
    "WHERE CREATED_DATE IS NOT NULL AND CREATED_DATE != '';\n",
    "\"\"\")\n",
    "\n",
    "# Step 7: Check if Datatype Fixes Were Applied\n",
    "df_transactions_info_after = pd.read_sql_query(query_check_transactions_columns, conn)\n",
    "df_users_info_after = pd.read_sql_query(query_check_users_columns, conn)\n",
    "print(\"Updated Column Information for df_transactions:\")\n",
    "print(df_transactions_info_after)\n",
    "print(\"Updated Column Information for df_users:\")\n",
    "print(df_users_info_after)\n",
    "\n",
    "# Step 8: Re-run the SQL Query\n",
    "query_top_spenders = \"\"\"\n",
    "WITH spending_percentiles AS (\n",
    "    SELECT total_spent\n",
    "    FROM (\n",
    "        SELECT USER_ID, SUM(FINAL_SALE) AS total_spent\n",
    "        FROM df_transactions\n",
    "        GROUP BY USER_ID\n",
    "    )\n",
    "    ORDER BY total_spent DESC\n",
    "    LIMIT (SELECT COUNT(DISTINCT USER_ID) * 0.10 FROM df_transactions)  \n",
    "),\n",
    "active_users AS (\n",
    "    SELECT ID AS USER_ID\n",
    "    FROM df_users\n",
    "    WHERE CREATED_DATE <= DATE('now', '-6 months')\n",
    "),\n",
    "monthly_activity AS (\n",
    "    SELECT \n",
    "        t.USER_ID, \n",
    "        strftime('%Y-%m', PURCHASE_DATE) AS purchase_month,  \n",
    "        COUNT(DISTINCT t.RECEIPT_ID) AS total_receipts, \n",
    "        SUM(FINAL_SALE) AS total_spending\n",
    "    FROM df_transactions t\n",
    "    JOIN active_users u ON t.USER_ID = u.USER_ID\n",
    "    GROUP BY t.USER_ID, purchase_month\n",
    "    HAVING total_receipts >= 3 \n",
    "    AND total_spending >= (SELECT MIN(total_spent) FROM spending_percentiles)\n",
    ")\n",
    "SELECT USER_ID, COUNT(DISTINCT purchase_month) AS active_months, SUM(total_spending) AS total_spent\n",
    "FROM monthly_activity\n",
    "GROUP BY USER_ID\n",
    "ORDER BY total_spent DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Step 9: Execute the Query and Handle Errors\n",
    "try:\n",
    "    top_power_users = pd.read_sql_query(query_top_spenders, conn)\n",
    "    # Close database connection\n",
    "    conn.close()\n",
    "\n",
    "    # Display results\n",
    "    import ace_tools as tools\n",
    "    tools.display_dataframe_to_user(name=\"Top 10% Spending Power Users\", dataframe=top_power_users)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error executing query: {e}\")\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5cc9b413-00a6-417a-8e5f-d2929b76a6f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT p.brand, SUM(t.sale) AS total_sales\nFROM transactions t\nJOIN products p ON t.barcode = p.barcode\nWHERE 'Dips & Salsa' IN (p.category_1, p.category_2, p.category_3, p.category_4)\nGROUP BY p.brand\nORDER BY total_sales DESC\nLIMIT 1;\n': no such table: transactions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: transactions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m query_leading_brand \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mSELECT p.brand, SUM(t.sale) AS total_sales\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mFROM transactions t\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124mLIMIT 1;\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Execute the query and store results in a DataFrame\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m leading_brand \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query_leading_brand, conn)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Close database connection\u001b[39;00m\n\u001b[1;32m     27\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT p.brand, SUM(t.sale) AS total_sales\nFROM transactions t\nJOIN products p ON t.barcode = p.barcode\nWHERE 'Dips & Salsa' IN (p.category_1, p.category_2, p.category_3, p.category_4)\nGROUP BY p.brand\nORDER BY total_sales DESC\nLIMIT 1;\n': no such table: transactions"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load the user's dataset into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"df_products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL Query to find the leading brand in the \"Dips & Salsa\" category by total sales\n",
    "query_leading_brand = \"\"\"\n",
    "SELECT p.brand, SUM(t.sale) AS total_sales\n",
    "FROM transactions t\n",
    "JOIN products p ON t.barcode = p.barcode\n",
    "WHERE 'Dips & Salsa' IN (p.category_1, p.category_2, p.category_3, p.category_4)\n",
    "GROUP BY p.brand\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 1;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "leading_brand = pd.read_sql_query(query_leading_brand, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n",
    "# Display results\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Leading Brand in Dips & Salsa Category\", dataframe=leading_brand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b798d3ac-43ef-48ed-974d-b4c2691404d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking DataFrames...\n",
      "df_transactions exists: True\n",
      "df_products exists: True\n",
      "df_transactions Sample:\n",
      "                             RECEIPT_ID PURCHASE_DATE               SCAN_DATE  \\\n",
      "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21 2024-08-21 14:19:06.539   \n",
      "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20 2024-07-20 09:50:24.206   \n",
      "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18 2024-08-19 15:38:56.813   \n",
      "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18 2024-06-19 11:03:37.468   \n",
      "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04 2024-07-05 15:56:43.549   \n",
      "\n",
      "  STORE_NAME                   USER_ID      BARCODE  FINAL_QUANTITY  \\\n",
      "0    WALMART  63b73a7f3d310dceeabd4758  15300014978             1.0   \n",
      "1       ALDI  62c08877baa38d1a1f6c211a      Unknown             0.0   \n",
      "2    WALMART  60842f207ac8b7729e472020      Unknown             1.0   \n",
      "3  FOOD LION  63fcd7cea4f8442c3386b589      Unknown             0.0   \n",
      "4   RANDALLS  6193231ae9b3d75037b0f928      Unknown             1.0   \n",
      "\n",
      "   FINAL_SALE  \n",
      "0        0.00  \n",
      "1        1.49  \n",
      "2        0.00  \n",
      "3        3.49  \n",
      "4        0.00  \n",
      "df_products Sample:\n",
      "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
      "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
      "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
      "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
      "3  Health & Wellness               Oral Care                   Toothpaste   \n",
      "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
      "\n",
      "  CATEGORY_4                                       MANUFACTURER  \\\n",
      "0    Unknown                                            Unknown   \n",
      "1    Unknown                                            Unknown   \n",
      "2    Unknown                           PLACEHOLDER MANUFACTURER   \n",
      "3    Unknown                                  COLGATE-PALMOLIVE   \n",
      "4    Unknown  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
      "\n",
      "             BRAND       BARCODE  \n",
      "0          Unknown  796494407820  \n",
      "1          Unknown   23278011028  \n",
      "2          ELECSOP  461817824225  \n",
      "3          COLGATE   35000466815  \n",
      "4  MAPLE HOLISTICS  806810850459  \n"
     ]
    }
   ],
   "source": [
    "# Check if datasets exist in memory\n",
    "print(\"Checking DataFrames...\")\n",
    "print(\"df_transactions exists:\", 'df_transactions' in globals())\n",
    "print(\"df_products exists:\", 'df_products' in globals())\n",
    "\n",
    "# Display a sample of the data if it exists\n",
    "if 'df_transactions' in globals():\n",
    "    print(\"df_transactions Sample:\")\n",
    "    print(df_transactions.head())\n",
    "\n",
    "if 'df_products' in globals():\n",
    "    print(\"df_products Sample:\")\n",
    "    print(df_products.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1c29d5f-17b0-404f-a0c8-2f7152b56c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables now available in SQLite:\n",
      "           name\n",
      "0  transactions\n",
      "1      products\n"
     ]
    }
   ],
   "source": [
    "# Ensure SQLite database is active\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Reload data into SQLite\n",
    "df_transactions.to_sql(\"transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Confirm the tables are now available\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(\"Tables now available in SQLite:\")\n",
    "print(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c1493080-9ebc-4443-956e-32106476b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Information for transactions:\n",
      "   cid            name       type  notnull dflt_value  pk\n",
      "0    0      RECEIPT_ID       TEXT        0       None   0\n",
      "1    1   PURCHASE_DATE  TIMESTAMP        0       None   0\n",
      "2    2       SCAN_DATE  TIMESTAMP        0       None   0\n",
      "3    3      STORE_NAME       TEXT        0       None   0\n",
      "4    4         USER_ID       TEXT        0       None   0\n",
      "5    5         BARCODE       TEXT        0       None   0\n",
      "6    6  FINAL_QUANTITY       REAL        0       None   0\n",
      "7    7      FINAL_SALE       REAL        0       None   0\n",
      "Column Information for products:\n",
      "   cid          name  type  notnull dflt_value  pk\n",
      "0    0    CATEGORY_1  TEXT        0       None   0\n",
      "1    1    CATEGORY_2  TEXT        0       None   0\n",
      "2    2    CATEGORY_3  TEXT        0       None   0\n",
      "3    3    CATEGORY_4  TEXT        0       None   0\n",
      "4    4  MANUFACTURER  TEXT        0       None   0\n",
      "5    5         BRAND  TEXT        0       None   0\n",
      "6    6       BARCODE  TEXT        0       None   0\n"
     ]
    }
   ],
   "source": [
    "query_check_transactions_columns = \"PRAGMA table_info(transactions);\"\n",
    "df_transactions_info = pd.read_sql_query(query_check_transactions_columns, conn)\n",
    "print(\"Column Information for transactions:\")\n",
    "print(df_transactions_info)\n",
    "\n",
    "query_check_products_columns = \"PRAGMA table_info(products);\"\n",
    "df_products_info = pd.read_sql_query(query_check_products_columns, conn)\n",
    "print(\"Column Information for products:\")\n",
    "print(df_products_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08063270-7bc6-4064-ad88-73431a3eb545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in SQLite Database:\n",
      "           name\n",
      "0  transactions\n",
      "1      products\n",
      "Column Information for transactions:\n",
      "   cid            name       type  notnull dflt_value  pk\n",
      "0    0      RECEIPT_ID       TEXT        0       None   0\n",
      "1    1   PURCHASE_DATE  TIMESTAMP        0       None   0\n",
      "2    2       SCAN_DATE  TIMESTAMP        0       None   0\n",
      "3    3      STORE_NAME       TEXT        0       None   0\n",
      "4    4         USER_ID       TEXT        0       None   0\n",
      "5    5         BARCODE       TEXT        0       None   0\n",
      "6    6  FINAL_QUANTITY       REAL        0       None   0\n",
      "7    7      FINAL_SALE       REAL        0       None   0\n",
      "Column Information for products:\n",
      "   cid          name  type  notnull dflt_value  pk\n",
      "0    0    CATEGORY_1  TEXT        0       None   0\n",
      "1    1    CATEGORY_2  TEXT        0       None   0\n",
      "2    2    CATEGORY_3  TEXT        0       None   0\n",
      "3    3    CATEGORY_4  TEXT        0       None   0\n",
      "4    4  MANUFACTURER  TEXT        0       None   0\n",
      "5    5         BRAND  TEXT        0       None   0\n",
      "6    6       BARCODE  TEXT        0       None   0\n",
      "      BRAND  total_sales\n",
      "0   Unknown    789851.96\n",
      "1  TOSTITOS    359214.44\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Reload the data into SQLite if it exists in memory\n",
    "df_transactions.to_sql(\"transactions\", conn, if_exists=\"replace\", index=False)\n",
    "df_products.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Step 1: Verify if the tables exist in SQLite\n",
    "query_check_tables = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql_query(query_check_tables, conn)\n",
    "print(\"Tables in SQLite Database:\")\n",
    "print(tables)\n",
    "\n",
    "# Step 2: Check column names in transactions\n",
    "query_check_transactions_columns = \"PRAGMA table_info(transactions);\"\n",
    "df_transactions_info = pd.read_sql_query(query_check_transactions_columns, conn)\n",
    "print(\"Column Information for transactions:\")\n",
    "print(df_transactions_info)\n",
    "\n",
    "# Step 3: Check column names in products\n",
    "query_check_products_columns = \"PRAGMA table_info(products);\"\n",
    "df_products_info = pd.read_sql_query(query_check_products_columns, conn)\n",
    "print(\"Column Information for products:\")\n",
    "print(df_products_info)\n",
    "\n",
    "# Step 4: Re-run the SQL Query to find the leading brand in \"Dips & Salsa\"\n",
    "\n",
    "query_leading_brand = \"\"\"\n",
    "SELECT p.BRAND, SUM(t.FINAL_SALE) AS total_sales\n",
    "FROM transactions t\n",
    "JOIN products p ON t.BARCODE = p.BARCODE\n",
    "WHERE 'Dips & Salsa' IN (p.CATEGORY_1, p.CATEGORY_2, p.CATEGORY_3, p.CATEGORY_4)\n",
    "GROUP BY p.BRAND\n",
    "ORDER BY total_sales DESC\n",
    "LIMIT 2;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Execute the query and store results in a DataFrame\n",
    "try:\n",
    "    leading_brand = pd.read_sql_query(query_leading_brand, conn)\n",
    "\n",
    "    print(leading_brand)\n",
    "except Exception as e:\n",
    "    print(f\"Error executing query: {e}\")\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "acb83632-0af6-422a-81a2-ed9013b12224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing query: Cannot operate on a closed database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Execute the corrected query\n",
    "try:\n",
    "    leading_brand = pd.read_sql_query(query_leading_brand, conn)\n",
    "    print(leading_brand)\n",
    "except Exception as e:\n",
    "    print(f\"Error executing query: {e}\")\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b366607-750b-4b94-929e-9ddc20b8ad45",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nWITH transaction_counts AS (\n    SELECT strftime('%Y', PURCHASE_DATE) AS year, COUNT(*) AS receipt_count\n    FROM transactions\n    GROUP BY year\n),\ngrowth AS (\n    SELECT \n        year,\n        receipt_count,\n        LAG(receipt_count) OVER (ORDER BY year) AS previous_year_count,\n        CASE \n            WHEN LAG(receipt_count) OVER (ORDER BY year) IS NOT NULL \n            THEN ROUND(((receipt_count - LAG(receipt_count) OVER (ORDER BY year)) * 100.0 / LAG(receipt_count) OVER (ORDER BY year)), 2)\n            ELSE NULL\n        END AS yoy_growth_percent\n    FROM transaction_counts\n)\nSELECT * FROM growth ORDER BY year DESC;\n': no such table: transactions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: transactions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Execute the queries and store results in DataFrames\u001b[39;00m\n\u001b[1;32m     78\u001b[0m user_growth \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query_user_growth, conn)\n\u001b[0;32m---> 79\u001b[0m transaction_growth \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query_transaction_growth, conn)\n\u001b[1;32m     80\u001b[0m sales_growth \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query_sales_growth, conn)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Close database connection\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nWITH transaction_counts AS (\n    SELECT strftime('%Y', PURCHASE_DATE) AS year, COUNT(*) AS receipt_count\n    FROM transactions\n    GROUP BY year\n),\ngrowth AS (\n    SELECT \n        year,\n        receipt_count,\n        LAG(receipt_count) OVER (ORDER BY year) AS previous_year_count,\n        CASE \n            WHEN LAG(receipt_count) OVER (ORDER BY year) IS NOT NULL \n            THEN ROUND(((receipt_count - LAG(receipt_count) OVER (ORDER BY year)) * 100.0 / LAG(receipt_count) OVER (ORDER BY year)), 2)\n            ELSE NULL\n        END AS yoy_growth_percent\n    FROM transaction_counts\n)\nSELECT * FROM growth ORDER BY year DESC;\n': no such table: transactions"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"df_transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# SQL Query 1: Year-over-Year Growth Based on User Registrations\n",
    "query_user_growth = \"\"\"\n",
    "WITH user_counts AS (\n",
    "    SELECT strftime('%Y', CREATED_DATE) AS year, COUNT(*) AS user_count\n",
    "    FROM df_users\n",
    "    GROUP BY year\n",
    "),\n",
    "growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        user_count,\n",
    "        LAG(user_count) OVER (ORDER BY year) AS previous_year_count,\n",
    "        CASE \n",
    "            WHEN LAG(user_count) OVER (ORDER BY year) IS NOT NULL \n",
    "            THEN ROUND(((user_count - LAG(user_count) OVER (ORDER BY year)) * 100.0 / LAG(user_count) OVER (ORDER BY year)), 2)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM user_counts\n",
    ")\n",
    "SELECT * FROM growth ORDER BY year DESC;\n",
    "\"\"\"\n",
    "\n",
    "# SQL Query 2: Year-over-Year Growth Based on Total Receipts Scanned\n",
    "query_transaction_growth = \"\"\"\n",
    "WITH transaction_counts AS (\n",
    "    SELECT strftime('%Y', PURCHASE_DATE) AS year, COUNT(*) AS receipt_count\n",
    "    FROM transactions\n",
    "    GROUP BY year\n",
    "),\n",
    "growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        receipt_count,\n",
    "        LAG(receipt_count) OVER (ORDER BY year) AS previous_year_count,\n",
    "        CASE \n",
    "            WHEN LAG(receipt_count) OVER (ORDER BY year) IS NOT NULL \n",
    "            THEN ROUND(((receipt_count - LAG(receipt_count) OVER (ORDER BY year)) * 100.0 / LAG(receipt_count) OVER (ORDER BY year)), 2)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM transaction_counts\n",
    ")\n",
    "SELECT * FROM growth ORDER BY year DESC;\n",
    "\"\"\"\n",
    "\n",
    "# SQL Query 3: Year-over-Year Growth Based on Total Sales (FINAL_SALE)\n",
    "query_sales_growth = \"\"\"\n",
    "WITH sales_counts AS (\n",
    "    SELECT strftime('%Y', PURCHASE_DATE) AS year, SUM(FINAL_SALE) AS total_sales\n",
    "    FROM transactions\n",
    "    GROUP BY year\n",
    "),\n",
    "growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        total_sales,\n",
    "        LAG(total_sales) OVER (ORDER BY year) AS previous_year_sales,\n",
    "        CASE \n",
    "            WHEN LAG(total_sales) OVER (ORDER BY year) IS NOT NULL \n",
    "            THEN ROUND(((total_sales - LAG(total_sales) OVER (ORDER BY year)) * 100.0 / LAG(total_sales) OVER (ORDER BY year)), 2)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM sales_counts\n",
    ")\n",
    "SELECT * FROM growth ORDER BY year DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the queries and store results in DataFrames\n",
    "user_growth = pd.read_sql_query(query_user_growth, conn)\n",
    "transaction_growth = pd.read_sql_query(query_transaction_growth, conn)\n",
    "sales_growth = pd.read_sql_query(query_sales_growth, conn)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"Year-over-Year User Growth\", user_growth)\n",
    "# Display results\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Year-over-Year User Growth\", dataframe=user_growth)\n",
    "tools.display_dataframe_to_user(name=\"Year-over-Year Transaction Growth\", dataframe=transaction_growth)\n",
    "tools.display_dataframe_to_user(name=\"Year-over-Year Sales Growth\", dataframe=sales_growth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a336347b-285a-4820-8116-1970713ea379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking DataFrames...\n",
      "df_users exists: True\n",
      "df_transactions exists: True\n",
      "df_users Sample:\n",
      "                         ID        CREATED_DATE          BIRTH_DATE STATE  \\\n",
      "0  5ef3b4f17053ab141787697d 2020-06-24 20:17:54 2000-08-11 00:00:00    CA   \n",
      "1  5ff220d383fcfc12622b96bc 2021-01-03 19:53:55 2001-09-24 04:00:00    PA   \n",
      "2  6477950aa55bb77a0e27ee10 2023-05-31 18:42:18 1994-10-28 00:00:00    FL   \n",
      "3  658a306e99b40f103b63ccf8 2023-12-26 01:46:22                 NaT    NC   \n",
      "4  653cf5d6a225ea102b7ecdc2 2023-10-28 11:51:50 1972-03-19 00:00:00    PA   \n",
      "\n",
      "  LANGUAGE   GENDER   AGE  \n",
      "0   es-419   female  25.0  \n",
      "1       en   female  24.0  \n",
      "2   es-419   female  31.0  \n",
      "3       en  Unknown   NaN  \n",
      "4       en   female  53.0  \n",
      "df_transactions Sample:\n",
      "                             RECEIPT_ID PURCHASE_DATE               SCAN_DATE  \\\n",
      "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21 2024-08-21 14:19:06.539   \n",
      "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20 2024-07-20 09:50:24.206   \n",
      "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18 2024-08-19 15:38:56.813   \n",
      "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18 2024-06-19 11:03:37.468   \n",
      "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04 2024-07-05 15:56:43.549   \n",
      "\n",
      "  STORE_NAME                   USER_ID      BARCODE  FINAL_QUANTITY  \\\n",
      "0    WALMART  63b73a7f3d310dceeabd4758  15300014978             1.0   \n",
      "1       ALDI  62c08877baa38d1a1f6c211a      Unknown             0.0   \n",
      "2    WALMART  60842f207ac8b7729e472020      Unknown             1.0   \n",
      "3  FOOD LION  63fcd7cea4f8442c3386b589      Unknown             0.0   \n",
      "4   RANDALLS  6193231ae9b3d75037b0f928      Unknown             1.0   \n",
      "\n",
      "   FINAL_SALE  \n",
      "0        0.00  \n",
      "1        1.49  \n",
      "2        0.00  \n",
      "3        3.49  \n",
      "4        0.00  \n"
     ]
    }
   ],
   "source": [
    "# Check if datasets exist\n",
    "print(\"Checking DataFrames...\")\n",
    "print(\"df_users exists:\", 'df_users' in globals())\n",
    "print(\"df_transactions exists:\", 'df_transactions' in globals())\n",
    "\n",
    "# Display a sample of the data if available\n",
    "if 'df_users' in globals():\n",
    "    print(\"df_users Sample:\")\n",
    "    print(df_users.head())\n",
    "\n",
    "if 'df_transactions' in globals():\n",
    "    print(\"df_transactions Sample:\")\n",
    "    print(df_transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b216c639-5698-432a-bbec-5b971afde9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables now available in SQLite:\n",
      "           name\n",
      "0      df_users\n",
      "1  transactions\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create a new in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"transactions\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Confirm that the tables exist\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(\"Tables now available in SQLite:\")\n",
    "print(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2863fef3-9371-4401-9300-2f224c11f8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables now available in SQLite:\n",
      "           name\n",
      "0      df_users\n",
      "1  transactions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Confirm that the tables exist\n",
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(\"Tables now available in SQLite:\")\n",
    "print(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a8b9512-f03b-4be4-a31e-07ef4f6dd8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  user_count  previous_year_count  yoy_growth_percent\n",
      "0   2024       11631              15464.0              -24.79\n",
      "1   2023       15464              26807.0              -42.31\n",
      "2   2022       26807              19159.0               39.92\n",
      "3   2021       19159              16883.0               13.48\n",
      "4   2020       16883               7093.0              138.02\n",
      "5   2019        7093               2168.0              227.17\n",
      "6   2018        2168                644.0              236.65\n",
      "7   2017         644                 70.0              820.00\n",
      "8   2016          70                 51.0               37.25\n",
      "9   2015          51                 30.0               70.00\n",
      "10  2014          30                  NaN                 NaN\n",
      "   year  receipt_count previous_year_count yoy_growth_percent\n",
      "0  2024          49818                None               None\n",
      "   year  total_sales previous_year_sales yoy_growth_percent\n",
      "0  2024    171160.25                None               None\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create a new in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "\n",
    "# Load data into SQLite\n",
    "df_users.to_sql(\"df_users\", conn, if_exists=\"replace\", index=False)\n",
    "df_transactions.to_sql(\"transactions\", conn, if_exists=\"replace\", index=False)\n",
    "# SQL Query 1: Year-over-Year Growth Based on User Registrations\n",
    "query_user_growth = \"\"\"\n",
    "WITH user_counts AS (\n",
    "    SELECT strftime('%Y', CREATED_DATE) AS year, COUNT(*) AS user_count\n",
    "    FROM df_users\n",
    "    GROUP BY year\n",
    "),\n",
    "growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        user_count,\n",
    "        LAG(user_count) OVER (ORDER BY year) AS previous_year_count,\n",
    "        CASE \n",
    "            WHEN LAG(user_count) OVER (ORDER BY year) IS NOT NULL \n",
    "            THEN ROUND(((user_count - LAG(user_count) OVER (ORDER BY year)) * 100.0 / LAG(user_count) OVER (ORDER BY year)), 2)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM user_counts\n",
    ")\n",
    "SELECT * FROM growth ORDER BY year DESC;\n",
    "\"\"\"\n",
    "\n",
    "# SQL Query 2: Year-over-Year Growth Based on Total Receipts Scanned\n",
    "query_transaction_growth = \"\"\"\n",
    "WITH transaction_counts AS (\n",
    "    SELECT strftime('%Y', PURCHASE_DATE) AS year, COUNT(*) AS receipt_count\n",
    "    FROM transactions\n",
    "    GROUP BY year\n",
    "),\n",
    "growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        receipt_count,\n",
    "        LAG(receipt_count) OVER (ORDER BY year) AS previous_year_count,\n",
    "        CASE \n",
    "            WHEN LAG(receipt_count) OVER (ORDER BY year) IS NOT NULL \n",
    "            THEN ROUND(((receipt_count - LAG(receipt_count) OVER (ORDER BY year)) * 100.0 / LAG(receipt_count) OVER (ORDER BY year)), 2)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM transaction_counts\n",
    ")\n",
    "SELECT * FROM growth ORDER BY year DESC;\n",
    "\"\"\"\n",
    "\n",
    "# SQL Query 3: Year-over-Year Growth Based on Total Sales (FINAL_SALE)\n",
    "query_sales_growth = \"\"\"\n",
    "WITH sales_counts AS (\n",
    "    SELECT strftime('%Y', PURCHASE_DATE) AS year, SUM(FINAL_SALE) AS total_sales\n",
    "    FROM transactions\n",
    "    GROUP BY year\n",
    "),\n",
    "growth AS (\n",
    "    SELECT \n",
    "        year,\n",
    "        total_sales,\n",
    "        LAG(total_sales) OVER (ORDER BY year) AS previous_year_sales,\n",
    "        CASE \n",
    "            WHEN LAG(total_sales) OVER (ORDER BY year) IS NOT NULL \n",
    "            THEN ROUND(((total_sales - LAG(total_sales) OVER (ORDER BY year)) * 100.0 / LAG(total_sales) OVER (ORDER BY year)), 2)\n",
    "            ELSE NULL\n",
    "        END AS yoy_growth_percent\n",
    "    FROM sales_counts\n",
    ")\n",
    "SELECT * FROM growth ORDER BY year DESC;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the queries and store results in DataFrames\n",
    "user_growth = pd.read_sql_query(query_user_growth, conn)\n",
    "transaction_growth = pd.read_sql_query(query_transaction_growth, conn)\n",
    "sales_growth = pd.read_sql_query(query_sales_growth, conn)\n",
    "print(user_growth)\n",
    "print(transaction_growth)\n",
    "print(sales_growth)\n",
    "# Close database connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe0e6a-5a0d-479a-9d9c-4266cd109283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
